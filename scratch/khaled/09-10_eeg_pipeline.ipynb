{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import terra\n",
    "import meerkat as mk\n",
    "from meerkat.contrib.eeg import build_stanford_eeg_dp\n",
    "from domino.utils import split_dp, balance_dp, merge_in_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load EEG datapanel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dp_art = build_stanford_eeg_dp.out(run_id=618) # with text constraint: 409\n",
    "dp=dp_art.load()\n",
    "dp.lz[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'file_id': 'DA05510C_1-3+',\n",
       " 'filepath': '/media/4tb_hdd/eeg_data/lpch/lpch/DA05510C_1-3+.eeghdf',\n",
       " 'fm_split': 'train',\n",
       " 'id': 'DA05510C_1-3+_-1.0',\n",
       " 'sz_start_index': -1.0,\n",
       " 'target': False,\n",
       " 'index': '0',\n",
       " 'input': LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60)),\n",
       " 'age': 0.006124270674784373,\n",
       " 'duration': 1325.9999999999998}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(dp)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "86091"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "balanced_dp_art = balance_dp.out(623) # with text constraint: 622\n",
    "balanced_dp = balanced_dp_art.load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "len(balanced_dp)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "58100"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## split data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dp_splits_art = split_dp.out(625) #split_dp(balanced_dp_art, split_on=\"file_id\")\n",
    "dp_splits = dp_splits_art.load()\n",
    "print(len(dp_splits))\n",
    "dp_splits.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44128\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id (PandasSeriesColumn)</th>\n",
       "      <th>split (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA1120VJ_1-1+</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA0551CN_1-1+</td>\n",
       "      <td>valid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA0552WC_1-2+</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA8312E5_1-7+</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA00106S_1-2+</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 5, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "thresh = 1\n",
    "age_labels = balanced_dp[\"age\"] > thresh\n",
    "sz_labels = balanced_dp[\"target\"]\n",
    "np.corrcoef([age_labels,sz_labels])[1,0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.0973282739180349"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Slice dp based on metadata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from domino.slices.eeg import EegSliceBuilder\n",
    "\n",
    "dp_age = EegSliceBuilder().build_correlation_setting(balanced_dp, correlate=\"age\", corr=0.9, n=8000, correlate_threshold=thresh)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "len(dp_age)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7998"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "age_labels = dp_age[\"age\"] > thresh\n",
    "sz_labels = dp_age[\"target\"]\n",
    "np.corrcoef([age_labels,sz_labels])[0,1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8999749937484369"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get multiple slices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# from domino.slices.eeg import collect_correlation_settings\n",
    "\n",
    "# # correlate_list = [\"age\"]\n",
    "# # corr_list = [0, 0.3, 0.5, 0.9]\n",
    "# # correlate_thresholds = [10]\n",
    "# # dp_slices_art = collect_correlation_slices(correlate_list, corr_list, correlate_thresholds)\n",
    "# dp_slices_art = collect_correlation_settings.out(516)\n",
    "# dp_slices = dp_slices_art.load()\n",
    "# dp_slices.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score slices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from domino.train import score_settings, score_model, train_model\n",
    "from domino.metrics import compute_model_metrics\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ksaab/Documents/meerkat/meerkat/nn/__init__.py:7: ExperimentalWarning: The `meerkat.nn` module is experimental and has limited test coverage. Proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "biased_model_dp = score_model.out(691).load()\n",
    "print(len(biased_model_dp))\n",
    "print(compute_model_metrics(biased_model_dp, num_iter=1000, flat=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "774\n",
      "{'overall_auroc': 0.7802465826856071, 'overall_recall': 0.9536585365853658, 'overall_precision': 0.6378466557911908, 'overall_f1_score': 0.7644183773216031, 'in_slice_0_auroc': 0.017647058823529415, 'in_slice_0_recall': 0.35, 'in_slice_0_precision': 0.2916666666666667, 'in_slice_0_f1_score': 0.31818181818181823, 'out_slice_auroc': 0.822966082908446, 'out_slice_recall': 0.9846153846153847, 'out_slice_precision': 0.6519524617996605, 'out_slice_f1_score': 0.7844739530132789}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# metric = \"auroc\"\n",
    "\n",
    "# scores_dp = score_slices.out(652).load() # on valid: 627, on test: 595\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}\"].data, color=\"green\")\n",
    "# #plt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}_mean\"].data, color=\"green\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}_lower\"].data, scores_dp[f\"in_slice_0_{metric}_upper\"].data, alpha=0.3, color=\"green\")\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}\"].data, color=\"red\")\n",
    "# #plt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}_mean\"].data, color=\"red\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}_lower\"].data, scores_dp[f\"out_slice_{metric}_upper\"].data, alpha=0.3, color=\"red\")\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}\"].data, color=\"blue\")\n",
    "# #lt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}_mean\"].data, color=\"blue\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}_lower\"].data, scores_dp[f\"overall_{metric}_upper\"].data, alpha=0.3, color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend([\"C = Y\", \"C != Y\",\"overall\"])\n",
    "# plt.ylabel(f\"mean {metric}\")\n",
    "# plt.xlabel(\"correlation strength\")\n",
    "# plt.title(\"EEG seizure prediction, age slicing\")\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# dp_ = train_model.inp(578)[\"dp\"].load()\n",
    "# mask = np.logical_and((dp_[\"slices\"].data[:,0]==1),dp_.lz[\"split\"]==\"valid\")\n",
    "\n",
    "# dp_[\"target\",\"binarized_age\"].lz[mask][-10:]\n",
    "# dp_[\"target\"].lz[mask].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Emed EEGs and Text using multimodal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from domino.emb.eeg import embed_eeg_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "score_dp_dev = score_model.out(677).load()\n",
    "score_dp_train = score_model.out(689).load()\n",
    "score_dp = mk.concat([score_dp_dev, score_dp_train])\n",
    "\n",
    "print(len(score_dp_train))\n",
    "print(len(score_dp_dev))\n",
    "print(len(score_dp))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5693\n",
      "771\n",
      "6464\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ksaab/Documents/meerkat/meerkat/columns/lambda_column.py:134: ConcatWarning: Concatenating LambdaColumns with different `fn`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "multimodal_corpus_dp = build_stanford_eeg_dp.out(run_id=696, load=True)  # for run with narrative: run_id = 696\n",
    "multimodal_split_dp = split_dp.out(697, load=True) # for run with narrative: run_id = 697\n",
    "multimodal_corpus_dp = merge_in_split(multimodal_corpus_dp, multimodal_split_dp)\n",
    "\n",
    "multimodal_corpus_dp_emb = embed_eeg_text.out(713,load=True) #(dp=multimodal_corpus_dp,model=terra.get(704, \"best_chkpt\")[\"model\"], layers={\"fc1\": \"model.fc1\"}, device=0, batch_size=1) \n",
    "eeg_corpus_dp_emb = embed_eeg_text.out(711,load=True)\n",
    "# for eeg only embed_eeg_text run_id = 711, model run_id=709\n",
    "# for multimodal run with narrative embed_eeg_text run_id = 713, model run_id = 704, \n",
    "# for multimodal run without narrative run_id=659\n",
    "\n",
    "print(len(multimodal_corpus_dp_emb))\n",
    "print(len(eeg_corpus_dp_emb))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6254\n",
      "6254\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score train samples in multimodal corpus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "valid_mask = multimodal_corpus_dp_emb[\"split\"]==\"valid\"\n",
    "train_mask = multimodal_corpus_dp_emb[\"split\"]==\"train\"\n",
    "dp_emb_train = multimodal_corpus_dp_emb.lz[train_mask]\n",
    "\n",
    "# get the average embedding of predicted seizure on the dev set\n",
    "sz_preds = biased_model_dp[\"output\"].argmax(1)\n",
    "pred_emb = biased_model_dp[\"fc1\"].lz[sz_preds].mean(0)\n",
    "\n",
    "#get the average embedding of seizures on the dev set\n",
    "sz_emb = biased_model_dp[\"fc1\"].lz[biased_model_dp[\"target\"]].mean(0)\n",
    "\n",
    "# score the training samples \n",
    "train_embs = dp_emb_train[\"fc1\"]\n",
    "train_scores = np.dot(train_embs, (pred_emb-sz_emb))\n",
    "dp_emb_train[\"scores\"] = train_scores\n",
    "\n",
    "(dp_emb_train.lz[(-train_scores).argsort()[:20]][\"age\"]< 1).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge multimodal and EEG embeddings in biased_model_dp"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# biased_model_emb_dp = embed_eeg_text(dp=biased_model_dp,model=terra.get(704, \"best_chkpt\")[\"model\"], layers={\"multimodal_fc1\": \"model.fc1\"}, device=0, batch_size=1)\n",
    "# biased_model_emb_dp = embed_eeg_text(dp=embed_eeg_text,model=terra.get(709, \"best_chkpt\")[\"model\"], layers={\"eeg_fc1\": \"model.fc1\"}, device=0, batch_size=1)\n",
    "biased_model_emb_dp = embed_eeg_text.out(718,load=True)\n",
    "print(len(biased_model_emb_dp))\n",
    "biased_model_emb_dp.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "774\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id (PandasSeriesColumn)</th>\n",
       "      <th>sz_start_index (NumpyArrayColumn)</th>\n",
       "      <th>fm_split (PandasSeriesColumn)</th>\n",
       "      <th>filepath (PandasSeriesColumn)</th>\n",
       "      <th>target (NumpyArrayColumn)</th>\n",
       "      <th>input (LambdaColumn)</th>\n",
       "      <th>duration (NumpyArrayColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "      <th>age (NumpyArrayColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "      <th>binarized_age (NumpyArrayColumn)</th>\n",
       "      <th>slices (NumpyArrayColumn)</th>\n",
       "      <th>split (PandasSeriesColumn)</th>\n",
       "      <th>output (ClassificationOutputColumn)</th>\n",
       "      <th>fc1 (TensorColumn)</th>\n",
       "      <th>multimodal_fc1 (NumpyArrayColumn)</th>\n",
       "      <th>eeg_fc1 (NumpyArrayColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZA0054I5_1-1+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>/media/4tb_hdd/eeg_data/stanford/stanford_mini/ZA0054I5_1-1+.eeghdf</td>\n",
       "      <td>True</td>\n",
       "      <td>LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60))</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>ZA0054I5_1-1+_3.0</td>\n",
       "      <td>66.137876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(1,))</td>\n",
       "      <td>valid</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([2]))</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([128]))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZA0054I5_1-1+</td>\n",
       "      <td>15.0</td>\n",
       "      <td>train</td>\n",
       "      <td>/media/4tb_hdd/eeg_data/stanford/stanford_mini/ZA0054I5_1-1+.eeghdf</td>\n",
       "      <td>True</td>\n",
       "      <td>LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60))</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>ZA0054I5_1-1+_15.0</td>\n",
       "      <td>66.137876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(1,))</td>\n",
       "      <td>valid</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([2]))</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([128]))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZA0054I5_1-1+</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "      <td>/media/4tb_hdd/eeg_data/stanford/stanford_mini/ZA0054I5_1-1+.eeghdf</td>\n",
       "      <td>True</td>\n",
       "      <td>LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60))</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>ZA0054I5_1-1+_4.0</td>\n",
       "      <td>66.137876</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(1,))</td>\n",
       "      <td>valid</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([2]))</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([128]))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZA0054I5_1-1+</td>\n",
       "      <td>18.0</td>\n",
       "      <td>train</td>\n",
       "      <td>/media/4tb_hdd/eeg_data/stanford/stanford_mini/ZA0054I5_1-1+.eeghdf</td>\n",
       "      <td>True</td>\n",
       "      <td>LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60))</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>ZA0054I5_1-1+_18.0</td>\n",
       "      <td>66.137876</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(1,))</td>\n",
       "      <td>valid</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([2]))</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([128]))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZA0054I5_1-1+</td>\n",
       "      <td>11.0</td>\n",
       "      <td>train</td>\n",
       "      <td>/media/4tb_hdd/eeg_data/stanford/stanford_mini/ZA0054I5_1-1+.eeghdf</td>\n",
       "      <td>True</td>\n",
       "      <td>LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f0628ce78b0>, clip_len=60))</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>ZA0054I5_1-1+_11.0</td>\n",
       "      <td>66.137876</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(1,))</td>\n",
       "      <td>valid</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([2]))</td>\n",
       "      <td>torch.Tensor(shape=torch.Size([128]))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 5, ncols: 17)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit and Score SDMs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from domino.sdm import MixtureModelSDM, SpotlightSDM\n",
    "from domino.metrics import compute_sdm_metrics, compute_bootstrap_ci\n",
    "\n",
    "sdm = MixtureModelSDM(\n",
    "    n_slices=10, \n",
    "    n_clusters=10, \n",
    "    weight_y_log_likelihood=10, \n",
    "    init_params=\"error\",\n",
    "    emb=\"multimodal_fc1\",\n",
    "    pca_components=128 \n",
    ")\n",
    "\n",
    "# sdm = SpotlightSDM(\n",
    "#     learning_rate=1e-3,\n",
    "#     n_slices=10, \n",
    "#     emb=\"eeg_fc1\",\n",
    "#     min_weight=10,\n",
    "# )\n",
    "\n",
    "biased_model_emb_dp[\"slices\"] = np.array([((biased_model_emb_dp[\"binarized_age\"]==0) * (biased_model_emb_dp[\"target\"]==1)),((biased_model_emb_dp[\"binarized_age\"]==1) * (biased_model_emb_dp[\"target\"]==0))]).T\n",
    "biased_model_emb_dp[\"pred\"] = biased_model_emb_dp[\"output\"][:,1].sigmoid().numpy()\n",
    "\n",
    "num_runs = 10\n",
    "top_auroc = []\n",
    "for n in range(num_runs):\n",
    "    # fit SDM\n",
    "    \n",
    "    sdm.fit(biased_model_emb_dp)\n",
    "    sdm_dp = sdm.transform(biased_model_emb_dp)\n",
    "\n",
    "    # score slices\n",
    "    slice_idx = 0\n",
    "    metrics_df = compute_sdm_metrics(sdm_dp)\n",
    "    metrics_df = metrics_df[metrics_df[\"slice_idx\"] == slice_idx]\n",
    "    top_auroc.append(metrics_df[\"auroc\"].max())\n",
    "    #metrics_df[metrics_df[\"slice_idx\"] == slice_idx].sort_values(by=\"auroc\", ascending=False)\n",
    "\n",
    "top_auroc = np.array(top_auroc)\n",
    "print(np.mean(top_auroc))\n",
    "print(compute_bootstrap_ci(top_auroc))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 40/100 [00:00<00:00, 649.48it/s]\n",
      " 73%|███████▎  | 73/100 [00:00<00:00, 784.33it/s]\n",
      " 29%|██▉       | 29/100 [00:00<00:00, 810.95it/s]\n",
      " 81%|████████  | 81/100 [00:00<00:00, 759.04it/s]\n",
      " 37%|███▋      | 37/100 [00:00<00:00, 642.42it/s]\n",
      " 63%|██████▎   | 63/100 [00:00<00:00, 463.36it/s]\n",
      " 40%|████      | 40/100 [00:00<00:00, 369.74it/s]\n",
      " 52%|█████▏    | 52/100 [00:00<00:00, 524.56it/s]\n",
      " 49%|████▉     | 49/100 [00:00<00:00, 757.69it/s]\n",
      " 47%|████▋     | 47/100 [00:00<00:00, 731.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.839973474801061\n",
      "{'mean': 0.839973474801061, 'lower': 0.8289350132625993, 'upper': 0.849990550397878}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# create vocabulary from all reports\n",
    "from domino.emb.eeg import generate_words_dp\n",
    "\n",
    "all_narratives = multimodal_corpus_dp[\"narrative\"].data\n",
    "words_dp = generate_words_dp(all_narratives, min_threshold=50)\n",
    "print(len(words_dp))\n",
    "words_dp.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1056\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>22102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mg</td>\n",
       "      <td>18075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>14418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>14246</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeg</td>\n",
       "      <td>13178</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 5, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from domino.emb.eeg import embed_words \n",
    "\n",
    "# embed words in vocab\n",
    "emb_words_dp = embed_words(words_dp,model=terra.get(704, \"best_chkpt\")[\"model\"], device=0, batch_size=1).load()\n",
    "emb_words_dp.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "task: embed_words, run_id=731\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CheXbert: skipping param linear_heads.0.weight\n",
      "CheXbert: skipping param linear_heads.0.bias\n",
      "CheXbert: skipping param linear_heads.1.weight\n",
      "CheXbert: skipping param linear_heads.1.bias\n",
      "CheXbert: skipping param linear_heads.2.weight\n",
      "CheXbert: skipping param linear_heads.2.bias\n",
      "CheXbert: skipping param linear_heads.3.weight\n",
      "CheXbert: skipping param linear_heads.3.bias\n",
      "CheXbert: skipping param linear_heads.4.weight\n",
      "CheXbert: skipping param linear_heads.4.bias\n",
      "CheXbert: skipping param linear_heads.5.weight\n",
      "CheXbert: skipping param linear_heads.5.bias\n",
      "CheXbert: skipping param linear_heads.6.weight\n",
      "CheXbert: skipping param linear_heads.6.bias\n",
      "CheXbert: skipping param linear_heads.7.weight\n",
      "CheXbert: skipping param linear_heads.7.bias\n",
      "CheXbert: skipping param linear_heads.8.weight\n",
      "CheXbert: skipping param linear_heads.8.bias\n",
      "CheXbert: skipping param linear_heads.9.weight\n",
      "CheXbert: skipping param linear_heads.9.bias\n",
      "CheXbert: skipping param linear_heads.10.weight\n",
      "CheXbert: skipping param linear_heads.10.bias\n",
      "CheXbert: skipping param linear_heads.11.weight\n",
      "CheXbert: skipping param linear_heads.11.bias\n",
      "CheXbert: skipping param linear_heads.12.weight\n",
      "CheXbert: skipping param linear_heads.12.bias\n",
      "CheXbert: skipping param linear_heads.13.weight\n",
      "CheXbert: skipping param linear_heads.13.bias\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ksaab/miniconda3/envs/domino/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e985ae5f7ff494b9ffe6de28554e409"
      },
      "text/plain": [
       "  0%|          | 0/1056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ksaab/miniconda3/envs/domino/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/tokenization_utils_base.py:2129: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "      <th>emb (NumpyArrayColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>22102</td>\n",
       "      <td>0</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mg</td>\n",
       "      <td>18075</td>\n",
       "      <td>1</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>14418</td>\n",
       "      <td>2</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>14246</td>\n",
       "      <td>3</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeg</td>\n",
       "      <td>13178</td>\n",
       "      <td>4</td>\n",
       "      <td>np.ndarray(shape=(128,))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 5, ncols: 4)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "pred_slice_idx = 0\n",
    "expl_dp = sdm.explain(words_dp=words_dp, data_dp=sdm_dp)\n",
    "expl_dp.lz[(-expl_dp[\"pred_slices\"][:, pred_slice_idx]).argsort()[:10]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>pred_slices (NumpyArrayColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>razavi</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>possibly</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norcuron</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>possible</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nihon</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>picu</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suspected</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tube</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>graber</td>\n",
       "      <td>np.ndarray(shape=(10,))</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 10, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('domino': conda)"
  },
  "interpreter": {
   "hash": "b006b217e8cb0199fc13ea6a087b3b77c18ca9d2bc7dc9a8383728a63838a653"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}