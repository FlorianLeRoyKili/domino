{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import terra\n",
    "import meerkat as mk\n",
    "from meerkat.contrib.eeg import build_stanford_eeg_dp\n",
    "from domino.utils import split_dp, balance_dp, merge_in_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "import eeghdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EEG datapanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_id': 'DA05510C_1-3+',\n",
       " 'filepath': '/media/4tb_hdd/eeg_data/lpch/lpch/DA05510C_1-3+.eeghdf',\n",
       " 'fm_split': 'train',\n",
       " 'id': 'DA05510C_1-3+_-1.0',\n",
       " 'sz_start_index': -1.0,\n",
       " 'target': False,\n",
       " 'index': '0',\n",
       " 'input': LambdaCell(fn=functools.partial(<function stanford_eeg_loader at 0x7f2fefc85e50>, clip_len=60)),\n",
       " 'age': 0.006124270674784373,\n",
       " 'duration': 1325.9999999999998}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_art = build_stanford_eeg_dp.out(run_id=618) # for 60sec: 618, with text constraint: 409\n",
    "dp=dp_art.load()\n",
    "dp.lz[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86091"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dp_art = balance_dp.out(623) # 928, 60 sec: 623, with text constraint: 622\n",
    "balanced_dp = balanced_dp_art.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(balanced_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id (PandasSeriesColumn)</th>\n",
       "      <th>split (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA1120VJ_1-1+</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA0551CN_1-1+</td>\n",
       "      <td>valid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA0552WC_1-2+</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA8312E5_1-7+</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA00106S_1-2+</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 5, ncols: 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_splits_art = split_dp(balanced_dp_art, split_on=\"file_id\")\n",
    "dp_splits = dp_splits_art.load()\n",
    "print(len(dp_splits))\n",
    "dp_splits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1786836562035982\n"
     ]
    }
   ],
   "source": [
    "thresh = 1\n",
    "age_labels = balanced_dp[\"age\"] < thresh\n",
    "sz_labels = balanced_dp[\"target\"]\n",
    "#np.corrcoef([age_labels,sz_labels])[1,0]\n",
    "print(age_labels.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice dp based on metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.slices.eeg import EegSliceBuilder\n",
    "\n",
    "#dp_age = EegSliceBuilder().build_correlation_setting(balanced_dp, correlate=\"age\", corr=0.0, n=8000, correlate_threshold=thresh)\n",
    "dp_age = EegSliceBuilder().build_rare_setting(balanced_dp, attribute=\"age\", attribute_thresh=1, slice_frac=0.001, n=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dp_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.46975\n"
     ]
    }
   ],
   "source": [
    "age_labels = dp_age[\"age\"] < thresh\n",
    "sz_labels = dp_age[\"target\"]\n",
    "#np.corrcoef([age_labels,sz_labels])[0,1]\n",
    "print(age_labels.mean())\n",
    "print(sz_labels.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get multiple slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from domino.slices.eeg import collect_correlation_settings\n",
    "\n",
    "# # correlate_list = [\"age\"]\n",
    "# # corr_list = [0, 0.3, 0.5, 0.9]\n",
    "# # correlate_thresholds = [10]\n",
    "# # dp_slices_art = collect_correlation_slices(correlate_list, corr_list, correlate_thresholds)\n",
    "# dp_slices_art = collect_correlation_settings.out(516)\n",
    "# dp_slices = dp_slices_art.load()\n",
    "# dp_slices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.train import score_settings, score_model, train_model\n",
    "from domino.metrics import compute_model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_model_dp = score_model.out(691).load()\n",
    "print(len(biased_model_dp))\n",
    "print(compute_model_metrics(biased_model_dp, num_iter=1000, flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# metric = \"auroc\"\n",
    "\n",
    "# scores_dp = score_slices.out(652).load() # on valid: 627, on test: 595\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}\"].data, color=\"green\")\n",
    "# #plt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}_mean\"].data, color=\"green\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"in_slice_0_{metric}_lower\"].data, scores_dp[f\"in_slice_0_{metric}_upper\"].data, alpha=0.3, color=\"green\")\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}\"].data, color=\"red\")\n",
    "# #plt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}_mean\"].data, color=\"red\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"out_slice_{metric}_lower\"].data, scores_dp[f\"out_slice_{metric}_upper\"].data, alpha=0.3, color=\"red\")\n",
    "\n",
    "# plt.plot(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}\"].data, color=\"blue\")\n",
    "# #lt.scatter(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}_mean\"].data, color=\"blue\")\n",
    "# #plt.fill_between(scores_dp[\"corr\"].data, scores_dp[f\"overall_{metric}_lower\"].data, scores_dp[f\"overall_{metric}_upper\"].data, alpha=0.3, color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend([\"C = Y\", \"C != Y\",\"overall\"])\n",
    "# plt.ylabel(f\"mean {metric}\")\n",
    "# plt.xlabel(\"correlation strength\")\n",
    "# plt.title(\"EEG seizure prediction, age slicing\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp_ = train_model.inp(578)[\"dp\"].load()\n",
    "# mask = np.logical_and((dp_[\"slices\"].data[:,0]==1),dp_.lz[\"split\"]==\"valid\")\n",
    "\n",
    "# dp_[\"target\",\"binarized_age\"].lz[mask][-10:]\n",
    "# dp_[\"target\"].lz[mask].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emed EEGs and Text using multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.emb.eeg import embed_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dp_dev = score_model.out(677).load()\n",
    "score_dp_train = score_model.out(689).load()\n",
    "score_dp = mk.concat([score_dp_dev, score_dp_train])\n",
    "\n",
    "print(len(score_dp_train))\n",
    "print(len(score_dp_dev))\n",
    "print(len(score_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_corpus_dp = build_stanford_eeg_dp.out(run_id=696, load=True)  # for run with narrative: run_id = 696\n",
    "multimodal_split_dp = split_dp.out(697, load=True) # for run with narrative: run_id = 697\n",
    "multimodal_corpus_dp = merge_in_split(multimodal_corpus_dp, multimodal_split_dp)\n",
    "\n",
    "multimodal_corpus_dp_emb = embed_eeg.out(743, load=True) #(dp=multimodal_corpus_dp,model=terra.get(715, \"best_chkpt\")[\"model\"], layers={\"fc1\": \"model.fc1\"}, device=0, batch_size=10) \n",
    "eeg_corpus_dp_emb = embed_eeg.out(711,load=True)\n",
    "# for eeg only embed_eeg_text run_id = 711, model run_id=709\n",
    "# for multimodal run with narrative and only 10 epochs embed_eeg_text run_id 743, model run_id 715\n",
    "# for multimodal run with narrative embed_eeg_text run_id = 713, model run_id = 704, \n",
    "# for multimodal run without narrative run_id=659\n",
    "\n",
    "print(len(multimodal_corpus_dp_emb))\n",
    "print(len(eeg_corpus_dp_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score train samples in multimodal corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mask = multimodal_corpus_dp_emb[\"split\"]==\"valid\"\n",
    "train_mask = multimodal_corpus_dp_emb[\"split\"]==\"train\"\n",
    "dp_emb_train = multimodal_corpus_dp_emb.lz[train_mask]\n",
    "\n",
    "# get the average embedding of predicted seizure on the dev set\n",
    "sz_preds = biased_model_dp[\"output\"].argmax(1)\n",
    "pred_emb = biased_model_dp[\"fc1\"].lz[sz_preds].mean(0)\n",
    "\n",
    "#get the average embedding of seizures on the dev set\n",
    "sz_emb = biased_model_dp[\"fc1\"].lz[biased_model_dp[\"target\"]].mean(0)\n",
    "\n",
    "# score the training samples \n",
    "train_embs = dp_emb_train[\"fc1\"]\n",
    "train_scores = np.dot(train_embs, (pred_emb-sz_emb))\n",
    "dp_emb_train[\"scores\"] = train_scores\n",
    "\n",
    "(dp_emb_train.lz[(-train_scores).argsort()[:20]][\"age\"]< 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge multimodal and EEG embeddings in biased_model_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biased_model_emb_dp = embed_eeg_text(dp=biased_model_dp,model=terra.get(704, \"best_chkpt\")[\"model\"], layers={\"multimodal_fc1\": \"model.fc1\"}, device=0, batch_size=1).load()\n",
    "#biased_model_emb_dp = embed_eeg_text(dp=biased_model_emb_dp,model=terra.get(709, \"best_chkpt\")[\"model\"], layers={\"eeg_fc1\": \"model.fc1\"}, device=0, batch_size=1).load()\n",
    "biased_model_emb_dp = embed_eeg_text.out(718,load=True)\n",
    "print(len(biased_model_emb_dp))\n",
    "biased_model_emb_dp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Score SDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.sdm import MixtureModelSDM, SpotlightSDM\n",
    "from domino.metrics import compute_sdm_metrics, compute_bootstrap_ci\n",
    "\n",
    "sdm = MixtureModelSDM(\n",
    "    n_slices=10, \n",
    "    n_clusters=10, \n",
    "    weight_y_log_likelihood=10, \n",
    "    init_params=\"error\",\n",
    "    emb=\"multimodal_fc1\",\n",
    "    pca_components=128 \n",
    ")\n",
    "\n",
    "# sdm = SpotlightSDM(\n",
    "#     learning_rate=1e-3,\n",
    "#     n_slices=10, \n",
    "#     emb=\"eeg_fc1\",\n",
    "#     min_weight=10,\n",
    "# )\n",
    "\n",
    "original_slices = biased_model_emb_dp[\"slices\"]\n",
    "biased_model_emb_dp[\"slices\"] = np.array([((biased_model_emb_dp[\"binarized_age\"]==0) * (biased_model_emb_dp[\"target\"]==1)),((biased_model_emb_dp[\"binarized_age\"]==1) * (biased_model_emb_dp[\"target\"]==0))]).T\n",
    "biased_model_emb_dp[\"pred\"] = biased_model_emb_dp[\"output\"][:,1].sigmoid().numpy()\n",
    "\n",
    "num_runs = 10\n",
    "top_auroc = []\n",
    "for n in range(num_runs):\n",
    "    # fit SDM\n",
    "    \n",
    "    sdm.fit(biased_model_emb_dp)\n",
    "    sdm_dp = sdm.transform(biased_model_emb_dp)\n",
    "\n",
    "    # score slices\n",
    "    slice_idx = 0\n",
    "    metrics_df = compute_sdm_metrics(sdm_dp)\n",
    "    metrics_df = metrics_df[metrics_df[\"slice_idx\"] == slice_idx]\n",
    "    top_auroc.append(metrics_df[\"auroc\"].max())\n",
    "    #metrics_df[metrics_df[\"slice_idx\"] == slice_idx].sort_values(by=\"auroc\", ascending=False)\n",
    "\n",
    "top_auroc = np.array(top_auroc)\n",
    "print(compute_bootstrap_ci(top_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary from all reports\n",
    "from domino.emb.eeg import generate_words_dp\n",
    "\n",
    "all_narratives = multimodal_corpus_dp[\"narrative\"].data\n",
    "words_dp = generate_words_dp(all_narratives, min_threshold=1)\n",
    "print(len(words_dp))\n",
    "words_dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ndxs = np.random.choice(len(words_dp),10)\n",
    "words_dp[random_ndxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.emb.eeg import embed_words \n",
    "\n",
    "# embed words in vocab\n",
    "emb_words_dp = embed_words(words_dp,model=terra.get(704, \"best_chkpt\")[\"model\"], device=0, batch_size=1).load()\n",
    "emb_words_dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biased_model_emb_dp[\"slices\"] = original_slices\n",
    "\n",
    "sdm.fit(biased_model_emb_dp)\n",
    "sdm_dp = sdm.transform(biased_model_emb_dp)\n",
    "\n",
    "# score slices\n",
    "slice_idx = 1\n",
    "metrics_df = compute_sdm_metrics(sdm_dp)\n",
    "metrics_df = metrics_df[metrics_df[\"slice_idx\"] == slice_idx]\n",
    "\n",
    "print(\"max auroc: \", metrics_df[\"auroc\"].max())\n",
    "pred_slice_idx = metrics_df[\"auroc\"].argmax()\n",
    "expl_dp = sdm.explain(words_dp=emb_words_dp, data_dp=sdm_dp)\n",
    "expl_dp.lz[(-expl_dp[\"pred_slices\"][:, pred_slice_idx]).argsort()[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_dp.lz[(-expl_dp[\"pred_slices\"][:, pred_slice_idx]).argsort()[10:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_dp.lz[(-expl_dp[\"pred_slices\"][:, pred_slice_idx]).argsort()[20:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc75dceca39a6c6bc36aa1cdee1aeb9a8529361fa67d06cea4bae31894d0887"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('domino': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
