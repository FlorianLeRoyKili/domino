{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import meerkat as mk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, recall_score, accuracy_score\n",
    "\n",
    "from domino.data.cxr import get_dp, build_cxr_df, get_cxr_activations\n",
    "\n",
    "import umap\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ksaab/Documents/meerkat/meerkat/nn/__init__.py:7: ExperimentalWarning: The `meerkat.nn` module is experimental and has limited test coverage. Proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Get a mosaic DataPanel with the data.\n",
    "df = build_cxr_df(root_dir=\"/media/4tb_hdd/siim\") #.out(load=True)\n",
    "dp = get_dp(df)\n",
    "#dp.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dp.lz[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'image_id': '1.2.276.0.7230010.3.1.4.8323329.6904.1517875201.850819',\n",
       " 'encoded_pixels': '-1',\n",
       " 'pmx': 0,\n",
       " 'filepath': '/media/4tb_hdd/siim/dicom-images-train/1.2.276.0.7230010.3.1.2.8323329.6904.1517875201.850818/1.2.276.0.7230010.3.1.3.8323329.6904.1517875201.850817/1.2.276.0.7230010.3.1.4.8323329.6904.1517875201.850819.dcm',\n",
       " 'chest_tube': nan,\n",
       " 'split': 'train',\n",
       " 'gaze_max_visit': nan,\n",
       " 'gaze_unique': nan,\n",
       " 'gaze_time': nan,\n",
       " 'gaze_diffusivity': nan,\n",
       " 'expert_label': nan,\n",
       " 'index': '0',\n",
       " 'input': LambdaCell(fn=cxr_loader),\n",
       " 'img': LambdaCell(fn=cxr_pil_loader)}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model_pth = \"/home/ksaab/Documents/domino/scratch/khaled/results/method_cnc/gaze_split_True/target_pmx/subgroup__chest_tube/lr_1e-05/wd_0.001/dropout_0/cw_0.8/domino/1nxwlapb/checkpoints/epoch=15-step=799.ckpt\"\n",
    "\n",
    "\n",
    "dp_erm = get_cxr_activations(dp=dp, model_path=model_pth, run_type=\"domino\")\n",
    "#dp_erm.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(85)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 85 \u001b[0;31m    act_dp = score(\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m        \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(86)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     84 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m    act_dp = score(\n",
      "\u001b[0m\u001b[0;32m---> 86 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m        \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m        layers={\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(87)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     85 \u001b[0;31m    act_dp = score(\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 87 \u001b[0;31m        \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m        layers={\n",
      "\u001b[0m\u001b[0;32m     89 \u001b[0;31m            \u001b[0;31m# \"block2\": model.cnn_encoder[-3],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(90)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     88 \u001b[0;31m        layers={\n",
      "\u001b[0m\u001b[0;32m     89 \u001b[0;31m            \u001b[0;31m# \"block2\": model.cnn_encoder[-3],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 90 \u001b[0;31m            \u001b[0;34m\"block3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     91 \u001b[0;31m            \u001b[0;34m\"block4\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     92 \u001b[0;31m        },\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(91)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     89 \u001b[0;31m            \u001b[0;31m# \"block2\": model.cnn_encoder[-3],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m            \u001b[0;34m\"block3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 91 \u001b[0;31m            \u001b[0;34m\"block4\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     92 \u001b[0;31m        },\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(88)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     86 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m        \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 88 \u001b[0;31m        layers={\n",
      "\u001b[0m\u001b[0;32m     89 \u001b[0;31m            \u001b[0;31m# \"block2\": model.cnn_encoder[-3],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m            \u001b[0;34m\"block3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(93)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     91 \u001b[0;31m            \u001b[0;34m\"block4\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcnn_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     92 \u001b[0;31m        },\n",
      "\u001b[0m\u001b[0;32m---> 93 \u001b[0;31m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     94 \u001b[0;31m    )\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mact_dp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/ksaab/Documents/domino/domino/data/cxr/__init__.py\u001b[0m(85)\u001b[0;36mget_cxr_activations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 85 \u001b[0;31m    act_dp = score(\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m        \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c628d074a87a45b88e5a2f266ad156ed"
      },
      "text/plain": [
       "  0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save a dp with mimic prediction columns "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # # get mimic activations\n",
    "# model_pth = \"/home/ksaab/Documents/domino/scratch/khaled/outputs/08-10_sabri_mimic/model_chkpt_runid4495.pt\"\n",
    "# dp_mimic = get_cxr_activations(dp=dp, model_path=model_pth, run_type=\"mimic\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mimic_labels = [\n",
    "#     \"atelectasis\",\n",
    "#     \"cardiomegaly\",\n",
    "#     \"consolidation\",\n",
    "#     \"edema\",\n",
    "#     \"enlarged_cardio\",\n",
    "#     \"fracture\",\n",
    "#     \"lung_opacity\",\n",
    "#     \"pleural_effusion\",\n",
    "#     \"pleural_other\",\n",
    "#     \"pneumonia\",\n",
    "#     \"pneumothorax\",\n",
    "#     \"support_devices\",\n",
    "#     \"lung_lesion\",\n",
    "#     \"no_finding\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# mimic_probs = dp_mimic[\"output\"].data.softmax(1)\n",
    "# mimic_probs[:,11] = 0 # remove support devices\n",
    "# mimic_probs[:,10] = 0 # remove pmx\n",
    "# mimic_preds = mimic_probs.argmax(1).numpy()\n",
    "\n",
    "# dp_withmimic = dp\n",
    "# for ndx, mimic_label in enumerate(mimic_labels):\n",
    "#     if not(mimic_label in [\"pneumothorax\", \"support_devices\"]):\n",
    "#         binary_preds = mimic_preds == ndx\n",
    "#         dp_withmimic[mimic_label] = binary_preds\n",
    "\n",
    "# mk.DataPanel.write(dp_withmimic,path=\"/media/4tb_hdd/siim/mimic_dp_09-06-21.dp\")\n",
    "# dp_withmimic.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ERM Performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dp_ = dp_erm\n",
    "\n",
    "test_mask = dp[\"split\"].data==\"test\" #np.logical_and(~train_mask, ~np.isnan(dp[\"chest_tube\"]))\n",
    "train_mask = np.logical_and(~test_mask,dp[\"chest_tube\"].data.astype(str) != \"nan\") #~np.isnan(dp[\"gaze_seq\"].data) #dp[\"gaze_seq\"].data != \"nan\"\n",
    "\n",
    "\n",
    "test_dp = dp_[test_mask]\n",
    "train_dp = dp_[train_mask]\n",
    "\n",
    "# overall performance\n",
    "if test_dp[\"output\"].data.shape[1] == 4:\n",
    "    # classes: 0: no tube no pmx, 1: no tube pmx, 2: tube no pmx, 3: tube pmx\n",
    "    test_probs = test_dp[\"output\"].data.softmax(1)\n",
    "    test_probs = np.max(test_probs[:,[1,3]].numpy(),axis=1)\n",
    "    train_probs = train_dp[\"output\"].data.softmax(1)\n",
    "    train_probs = np.max(train_probs[:,[1,3]].numpy(),axis=1)\n",
    "    \n",
    "else:\n",
    "    test_probs = test_dp[\"output\"].data[:,1].sigmoid()\n",
    "    train_probs = train_dp[\"output\"].data[:,1].sigmoid()\n",
    "\n",
    "test_labels = test_dp[\"pmx\"].data\n",
    "tubes_mask = np.array(test_dp[\"chest_tube\"] == 1)\n",
    "notubes_mask = np.array(test_dp[\"chest_tube\"] == 0)\n",
    "\n",
    "train_labels = train_dp[\"pmx\"].data\n",
    "train_tubes_mask = np.array(train_dp[\"chest_tube\"] == 1)\n",
    "train_notubes_mask = np.array(train_dp[\"chest_tube\"] == 0)\n",
    "\n",
    "print(len(test_labels))\n",
    "print(len(train_labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Train set:\")\n",
    "print(f\"\\tOverall AUROC: {roc_auc_score(train_labels,train_probs):.3f}\")\n",
    "\n",
    "neg_mask = np.array(train_labels == 0)\n",
    "pos_mask = np.array(train_labels == 1)\n",
    "tube_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,train_tubes_mask))\n",
    "notube_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,train_notubes_mask))\n",
    "\n",
    "tube_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,train_tubes_mask))\n",
    "notube_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,train_notubes_mask))\n",
    "\n",
    "mask = np.logical_or(np.logical_and(pos_mask,train_notubes_mask), np.logical_and(neg_mask,train_tubes_mask))\n",
    "print(f\"\\tAll negatives have tubes, All positives have no tube, AUROC: {roc_auc_score(train_labels[mask],train_probs[mask]):.3f}\")\n",
    "\n",
    "\n",
    "print(\"Val set:\")\n",
    "print(f\"\\tOverall AUROC: {roc_auc_score(test_labels,test_probs):.3f}\")\n",
    "\n",
    "# # AUROC performance on subset that has tube labels\n",
    "\n",
    "# print(f\"With tubes AUROC: {roc_auc_score(test_labels[tubes_mask],test_probs[tubes_mask]):.3f}\")\n",
    "\n",
    "# # AUROC performance on subset that has no tube labels\n",
    "# print(f\"Without tubes AUROC: {roc_auc_score(test_labels[notubes_mask],test_probs[notubes_mask]):.3f}\")\n",
    "\n",
    "neg_mask = np.array(test_labels == 0)\n",
    "pos_mask = np.array(test_labels == 1)\n",
    "tube_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,tubes_mask))\n",
    "notube_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,notubes_mask))\n",
    "\n",
    "#print(f\"All positives have tubes, AUROC: {roc_auc_score(test_labels[tube_in_pos_mask],test_probs[tube_in_pos_mask]):.3f}\")\n",
    "#print(f\"All positives have no tubes, AUROC: {roc_auc_score(test_labels[notube_in_pos_mask],test_probs[notube_in_pos_mask]):.3f}\")\n",
    "\n",
    "tube_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,tubes_mask))\n",
    "notube_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,notubes_mask))\n",
    "\n",
    "#print(f\"All negatives have tubes, AUROC: {roc_auc_score(test_labels[tube_in_neg_mask],test_probs[tube_in_neg_mask]):.3f}\")\n",
    "#print(f\"All negatives have no tubes, AUROC: {roc_auc_score(test_labels[notube_in_neg_mask],test_probs[notube_in_neg_mask]):.3f}\")\n",
    "\n",
    "mask = np.logical_or(np.logical_and(pos_mask,notubes_mask), np.logical_and(neg_mask,tubes_mask))\n",
    "print(f\"\\tAll negatives have tubes, All positives have no tube, AUROC: {roc_auc_score(test_labels[mask],test_probs[mask]):.3f}\")\n",
    "nopmx_notube_mask = np.logical_and(neg_mask,notubes_mask)\n",
    "nopmx_tube_mask = np.logical_and(neg_mask,tubes_mask)\n",
    "pmx_notube_mask = np.logical_and(pos_mask,notubes_mask)\n",
    "pmx_tube_mask = np.logical_and(pos_mask,tubes_mask)\n",
    "\n",
    "subgroup_accuracies = np.array([\n",
    "    accuracy_score(test_labels[nopmx_notube_mask],test_probs[nopmx_notube_mask]>0.5),\n",
    "    accuracy_score(test_labels[nopmx_tube_mask],test_probs[nopmx_tube_mask]>0.5),\n",
    "    accuracy_score(test_labels[pmx_notube_mask],test_probs[pmx_notube_mask]>0.5),\n",
    "    accuracy_score(test_labels[pmx_tube_mask],test_probs[pmx_tube_mask]>0.5),\n",
    "    ])\n",
    "print(f\"\\tRobust val acc: {subgroup_accuracies.min():.3f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.logical_and(neg_mask,tubes_mask).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.logical_and(pos_mask,notubes_mask).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Umap analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed_train = dp_erm[\"block4\"][train_mask].reshape(-1,2048,7*7).mean(2)\n",
    "print(embed_train.shape)\n",
    "\n",
    "embed_test = dp_erm[\"block4\"][test_mask].reshape(-1,2048,7*7).mean(2)\n",
    "print(embed_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reducer = umap.UMAP()\n",
    "embed_umap_train = reducer.fit_transform(embed_train)\n",
    "print(embed_umap_train.shape)\n",
    "\n",
    "embed_umap_test = reducer.fit_transform(embed_test)\n",
    "print(embed_umap_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_labels = dp_[train_mask][\"pmx\"].data\n",
    "train_tubes = dp_[train_mask][\"chest_tube\"].data\n",
    "\n",
    "test_labels = dp_[test_mask][\"pmx\"].data\n",
    "test_tubes = dp_[test_mask][\"chest_tube\"].data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groupid_to_name = [\"no pmx, no tube\", \"pmx, no tube\", \"no pmx, tube\", \"pmx, tube\"]\n",
    "groupid_to_color = [\"green\", \"red\", \"lightgreen\", \"pink\"]\n",
    "\n",
    "train_group_ids = (2*train_tubes + train_labels).astype(int)\n",
    "train_names = [groupid_to_name[groupid] for groupid in train_group_ids]\n",
    "train_colors = [groupid_to_color[groupid] for groupid in train_group_ids]\n",
    "test_group_ids = (2*test_tubes + test_labels).astype(int)\n",
    "test_colors = [groupid_to_color[groupid] for groupid in test_group_ids]\n",
    "\n",
    "\n",
    "centroids_train = np.array([embed_umap_train[train_group_ids==ndx].mean(0) for ndx in range(4)])\n",
    "centroids_test = np.array([embed_umap_test[test_group_ids==ndx].mean(0) for ndx in range(4)])\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(15,5))\n",
    "axs[0].scatter(embed_umap_train[:,0],embed_umap_train[:,1],c=train_colors,s=15)\n",
    "for ndx in range(4):\n",
    "    axs[0].scatter(centroids_train[ndx,0],centroids_train[ndx,1],label=groupid_to_name[ndx],s=300,marker=\"*\",c=groupid_to_color[ndx],edgecolors='k',linewidth=2)\n",
    "axs[0].set_title(\"Train embeddings\")\n",
    "\n",
    "axs[1].scatter(embed_umap_test[:,0],embed_umap_test[:,1],c=test_colors,s=30)\n",
    "axs[1].set_title(\"Test embeddings\")\n",
    "for ndx in range(4):\n",
    "    axs[1].scatter(centroids_test[ndx,0],centroids_test[ndx,1],label=groupid_to_name[ndx],s=500,marker=\"*\",c=groupid_to_color[ndx],edgecolors='k',linewidth=2)\n",
    "axs[1].legend(bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyzing correlations in the train set with mimic predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dp_ = dp_erm\n",
    "\n",
    "train_probs = dp_[train_mask][\"output\"].data[:,1].sigmoid()\n",
    "train_labels = dp_[train_mask][\"pmx\"].data\n",
    "\n",
    "train_tubes_mask = np.array(dp_[train_mask][\"chest_tube\"] == 1)\n",
    "\n",
    "train_notubes_mask = np.array(dp_[train_mask][\"chest_tube\"] == 0)\n",
    "\n",
    "train_neg_mask = np.array(dp_[train_mask][\"pmx\"] == 0)\n",
    "train_pos_mask = np.array(dp_[train_mask][\"pmx\"] == 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "train_mimic_probs = dp_mimic[train_mask][\"output\"].data.sigmoid()\n",
    "train_mimic_probs[:,11] = 0 # remove support devices\n",
    "train_mimic_probs[:,10] = 0 # remove pmx\n",
    "#mimic_probs[:,0] = -1e10 # remove atelectasis\n",
    "#mimic_probs[:,7] = -1e10 # remove pleural_effusion\n",
    "train_mimic_preds = train_mimic_probs.argmax(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,axs = plt.subplots(2,2,sharex=True, sharey=True, figsize=(15,8))\n",
    "\n",
    "\n",
    "# negatives without tubes\n",
    "mask = np.logical_and(train_neg_mask,train_notubes_mask)\n",
    "y_hist, x_hist = np.histogram(train_mimic_preds[mask],bins=np.array(range(15))-0.1,density=True)\n",
    "axs[0,0].bar(range(14),y_hist)\n",
    "axs[0,0].set_title(f\"Negatives Without Tubes ({mask.sum()})\")\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# negatives with tubes\n",
    "mask = np.logical_and(train_neg_mask,train_tubes_mask)\n",
    "y_hist, x_hist = np.histogram(train_mimic_preds[mask],bins=np.array(range(15))-0.1,density=True)\n",
    "axs[0,1].bar(range(14),y_hist)\n",
    "axs[0,1].set_title(f\"Negatives With Tubes ({mask.sum()})\")\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# positives without tubes\n",
    "mask = np.logical_and(train_pos_mask,train_notubes_mask)\n",
    "y_hist, x_hist = np.histogram(train_mimic_preds[mask],bins=np.array(range(15))-0.1,density=True)\n",
    "axs[1,0].bar(range(14),y_hist)\n",
    "axs[1,0].set_title(f\"Positives Without Tubes ({mask.sum()})\")\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# positives with tubes\n",
    "mask = np.logical_and(train_pos_mask,train_tubes_mask)\n",
    "y_hist, x_hist = np.histogram(train_mimic_preds[mask],bins=np.array(range(15))-0.1,density=True)\n",
    "axs[1,1].bar(range(14),y_hist)\n",
    "axs[1,1].set_title(f\"Positives With Tubes ({mask.sum()})\")\n",
    "\n",
    "axs[1,0].set_xticks(range(14))\n",
    "axs[1,0].set_xticklabels(mimic_labels,rotation=90)\n",
    "axs[1,1].set_xticks(range(14))\n",
    "axs[1,1].set_xticklabels(mimic_labels,rotation=90)\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "#plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View gap between mimic classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mimic_class = \"pleural_effusion\"\n",
    "class_ndx = np.argmax(np.array(mimic_labels)==mimic_class)\n",
    "\n",
    "test_mimic_probs = dp_mimic[test_mask][\"output\"].data[:,class_ndx].sigmoid()\n",
    "test_mimic_preds = np.array(test_mimic_probs > 0.5)\n",
    "\n",
    "dp_ = dp_erm\n",
    "\n",
    "train_mask = dp[\"gaze_seq\"].data != \"nan\"\n",
    "test_mask = np.logical_and(~train_mask, ~np.isnan(dp[\"chest_tube\"]))\n",
    "\n",
    "# overall performance\n",
    "print(f\"Overall AUROC: {roc_auc_score(test_labels,test_probs):.3f}\")\n",
    "\n",
    "# AUROC performance on subset that has tube labels\n",
    "mimic_mask = np.array(test_mimic_preds == 1)\n",
    "print(f\"With {mimic_class} AUROC: {roc_auc_score(test_labels[mimic_mask],test_probs[mimic_mask]):.3f}\")\n",
    "\n",
    "# AUROC performance on subset that has no tube labels\n",
    "nomimic_mask = np.array(test_mimic_preds == 0)\n",
    "print(f\"Without {mimic_class} AUROC: {roc_auc_score(test_labels[nomimic_mask],test_probs[nomimic_mask]):.3f}\")\n",
    "\n",
    "mimic_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,mimic_mask))\n",
    "nomimic_in_pos_mask = np.logical_or(neg_mask,np.logical_and(pos_mask,nomimic_mask))\n",
    "\n",
    "print(f\"All positives have {mimic_class}, AUROC: {roc_auc_score(test_labels[mimic_in_pos_mask],test_probs[mimic_in_pos_mask]):.3f}\")\n",
    "print(f\"All positives have no {mimic_class}, AUROC: {roc_auc_score(test_labels[nomimic_in_pos_mask],test_probs[nomimic_in_pos_mask]):.3f}\")\n",
    "\n",
    "mimic_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,mimic_mask))\n",
    "nomimic_in_neg_mask = np.logical_or(pos_mask,np.logical_and(neg_mask,nomimic_mask))\n",
    "\n",
    "print(f\"All negatives have {mimic_class}, AUROC: {roc_auc_score(test_labels[mimic_in_neg_mask],test_probs[mimic_in_neg_mask]):.3f}\")\n",
    "print(f\"All negatives have no {mimic_class}, AUROC: {roc_auc_score(test_labels[nomimic_in_neg_mask],test_probs[nomimic_in_neg_mask]):.3f}\")\n",
    "\n",
    "mask = np.logical_or(np.logical_and(pos_mask,nomimic_mask), np.logical_and(neg_mask,mimic_mask))\n",
    "print(f\"All negatives have {mimic_class}, All positives have no {mimic_class}, AUROC: {roc_auc_score(test_labels[mask],test_probs[mask]):.3f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analying errors with mimic predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mimic_probs = dp_mimic[test_mask][\"output\"].data.sigmoid()\n",
    "mimic_probs[:,11] = 0 # remove support devices\n",
    "mimic_probs[:,10] = 0 # remove pmx\n",
    "#mimic_probs[:,0] = -1e10 # remove atelectasis\n",
    "#mimic_probs[:,7] = -1e10 # remove pleural_effusion\n",
    "mimic_preds = mimic_probs.argmax(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find threshold that achieves XX% recall\n",
    "recall = 0.55\n",
    "best_thresh = -1\n",
    "best_recall = -1\n",
    "for thresh in np.arange(0,1,0.01):\n",
    "    test_preds_ = test_probs > thresh\n",
    "    recall_ = recall_score(test_labels,test_preds_)\n",
    "    if np.abs(recall_-recall) < np.abs(best_recall-recall):\n",
    "        best_thresh = thresh\n",
    "        best_recall = recall_\n",
    "\n",
    "print(best_recall)\n",
    "print(best_thresh)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thresh = best_thresh\n",
    "\n",
    "fig,axs = plt.subplots(2,2,sharex=True, sharey=True, figsize=(15,8))\n",
    "\n",
    "\n",
    "# negatives without tubes\n",
    "mask = np.logical_and(neg_mask,notubes_mask)\n",
    "error_mask = test_probs[mask] > thresh\n",
    "error_mimic_preds = mimic_preds[mask][error_mask]\n",
    "\n",
    "y_hist, x_hist = np.histogram(error_mimic_preds,bins=np.array(range(15))-0.1,density=True)\n",
    "axs[0,0].bar(range(14),y_hist)#/mask.sum())\n",
    "axs[0,0].set_title(f\"Errors in Negatives Without Tubes ({error_mask.sum()}/{mask.sum()})\")\n",
    "#axs[0,0].set_ylabel(\"Percentage in subset\")\n",
    "\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# negatives with tubes\n",
    "mask = np.logical_and(neg_mask,tubes_mask)\n",
    "error_mask = test_probs[mask] > thresh\n",
    "error_mimic_preds = mimic_preds[mask][error_mask]\n",
    "\n",
    "y_hist, x_hist = np.histogram(error_mimic_preds,bins=np.array(range(15))-0.1,density=True)\n",
    "axs[0,1].bar(range(14),y_hist)#/mask.sum())\n",
    "axs[0,1].set_title(f\"Errors in Negatives With Tubes ({error_mask.sum()}/{mask.sum()})\")\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# positives without tubes\n",
    "mask = np.logical_and(pos_mask,notubes_mask)\n",
    "error_mask = test_probs[mask] < thresh\n",
    "error_mimic_preds = mimic_preds[mask][error_mask]\n",
    "\n",
    "y_hist, x_hist = np.histogram(error_mimic_preds,bins=np.array(range(15))-0.1,density=True)\n",
    "axs[1,0].bar(range(14),y_hist)#/mask.sum())\n",
    "axs[1,0].set_title(f\"Errors in Positives Without Tubes ({error_mask.sum()}/{mask.sum()})\")\n",
    "#axs[1,0].set_ylabel(\"Percentage in subset\")\n",
    "\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "# positives with tubes\n",
    "mask = np.logical_and(pos_mask,tubes_mask)\n",
    "error_mask = test_probs[mask] < thresh\n",
    "error_mimic_preds = mimic_preds[mask][error_mask]\n",
    "\n",
    "y_hist, x_hist = np.histogram(error_mimic_preds,bins=np.array(range(15))-0.1,density=True)\n",
    "axs[1,1].bar(range(14),y_hist)#/mask.sum())\n",
    "axs[1,1].set_title(f\"Errors in Positives With Tubes ({error_mask.sum()}/{mask.sum()})\")\n",
    "\n",
    "axs[1,0].set_xticks(range(14))\n",
    "axs[1,0].set_xticklabels(mimic_labels,rotation=90)\n",
    "axs[1,1].set_xticks(range(14))\n",
    "axs[1,1].set_xticklabels(mimic_labels,rotation=90)\n",
    "print(np.array(100*y_hist).astype(int))\n",
    "\n",
    "#plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('domino': conda)"
  },
  "interpreter": {
   "hash": "b006b217e8cb0199fc13ea6a087b3b77c18ca9d2bc7dc9a8383728a63838a653"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}