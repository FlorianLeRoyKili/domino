{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from domino.slices import collect_settings\n",
    "from domino.slices.celeba import CelebASliceBuilder\n",
    "from domino.evaluate import run_sdm, score_sdms\n",
    "from domino.train import train_settings\n",
    "import numpy as np\n",
    "import terra"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sabri/code/meerkat/meerkat/nn/__init__.py:7: ExperimentalWarning: The `meerkat.nn` module is experimental and has limited test coverage. Proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from domino.emb.clip import get_wiki_words\n",
    "#dp = get_wiki_words(top_k=25_000, eng_only=True).load()\n",
    "word_dp = get_wiki_words.out().load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from domino.emb.clip import generate_phrases, CELEBA_PHRASE_TEMPLATES\n",
    "phrase_dp = generate_phrases(word_dp[:100], templates=CELEBA_PHRASE_TEMPLATES, num_candidates=1_00)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "703cada96a934ce199096d6c670b8077"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e935e2041ee46648bc69939768fa067"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(13.4990, device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Cannot create column out of data of type <class 'numpy.float32'>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20401/140910958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdomino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCELEBA_PHRASE_TEMPLATES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mphrase_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCELEBA_PHRASE_TEMPLATES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1_00\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sabri/code/domino/domino/emb/clip.py\u001b[0m in \u001b[0;36mgenerate_phrases\u001b[0;34m(word_dp, templates, device, k, bert_size, num_candidates)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prob\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_phrase\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     return mk.DataPanel.from_pandas(candidate_phrases)[\"output_phrase\"].map(\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0m_forward_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_batched_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/provenance.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_provenance_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0margs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/mixins/mapping.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, is_batched_fn, batch_size, drop_last_batch, num_workers, output_type, materialize, pbar, mmap, mmap_path, flush_size, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 ):\n\u001b[1;32m    100\u001b[0m                     curr_output_type = (\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAbstractColumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_type_mapping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/columns/abstract.py\u001b[0m in \u001b[0;36mfrom_data\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mListColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot create column out of data of type {type(data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAbstractColumn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create column out of data of type <class 'numpy.float32'>"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "phrase_dp.sort_values(\"prob\", ascending=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>24.308901</td>\n",
       "      <td>a photo of a person with the same name.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>24.415701</td>\n",
       "      <td>a photo of a person sitting next to him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>24.538908</td>\n",
       "      <td>a photo of a person standing next to him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>26.439959</td>\n",
       "      <td>a photo of a person leaning against a wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>26.592392</td>\n",
       "      <td>a photo of a person sitting at a table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>1789.102661</td>\n",
       "      <td>a photo of a person river had knew.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>1883.718872</td>\n",
       "      <td>a photo of a person in or player ).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>2099.983887</td>\n",
       "      <td>a photo of a person.. director \".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>2396.800293</td>\n",
       "      <td>a photo of a person river helped met.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12203</th>\n",
       "      <td>2465.095215</td>\n",
       "      <td>a photo of a person river helped knew.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              prob                                         text\n",
       "698      24.308901      a photo of a person with the same name.\n",
       "420      24.415701     a photo of a person sitting next to him.\n",
       "510      24.538908    a photo of a person standing next to him.\n",
       "305      26.439959  a photo of a person leaning against a wall.\n",
       "4877     26.592392      a photo of a person sitting at a table.\n",
       "...            ...                                          ...\n",
       "10808  1789.102661          a photo of a person river had knew.\n",
       "7817   1883.718872          a photo of a person in or player ).\n",
       "7710   2099.983887            a photo of a person.. director \".\n",
       "13046  2396.800293        a photo of a person river helped met.\n",
       "12203  2465.095215       a photo of a person river helped knew.\n",
       "\n",
       "[14400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2').to(0)\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "scores = []\n",
    "for text in tqdm(candidate_sents[\"output_phrase\"]):\n",
    "    tokens_tensor = gpt_tokenizer.encode( text, add_special_tokens=False, return_tensors=\"pt\").to(0) \n",
    "    loss=gpt_model(tokens_tensor, labels=tokens_tensor)[0]\n",
    "    scores.append( \n",
    "        {\"prob\": np.exp(loss.cpu().detach().numpy()), \"text\": text}       \n",
    "    )\n",
    "dp = pd.DataFrame(scores)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 68.04it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dp.sort_values(\"prob\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>56.578079</td>\n",
       "      <td>a photo of a person in the sea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>58.034519</td>\n",
       "      <td>a photo of a person with a guitar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>61.561375</td>\n",
       "      <td>a photo of a person walking through traffic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>61.679295</td>\n",
       "      <td>a photo of a person in another picture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>67.137917</td>\n",
       "      <td>a photo of a person with a debt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1872.045166</td>\n",
       "      <td>a photo of a person constitution paper.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>1957.345947</td>\n",
       "      <td>a photo of a person ferryeded.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2780.082520</td>\n",
       "      <td>a photo of a person cooper had from.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3535.363525</td>\n",
       "      <td>a photo of a person regional orized.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4481.204102</td>\n",
       "      <td>a photo of a person landmark orized.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prob                                          text\n",
       "439    56.578079               a photo of a person in the sea.\n",
       "68     58.034519            a photo of a person with a guitar.\n",
       "648    61.561375  a photo of a person walking through traffic.\n",
       "487    61.679295       a photo of a person in another picture.\n",
       "504    67.137917              a photo of a person with a debt.\n",
       "..           ...                                           ...\n",
       "376  1872.045166       a photo of a person constitution paper.\n",
       "936  1957.345947                a photo of a person ferryeded.\n",
       "293  2780.082520          a photo of a person cooper had from.\n",
       "220  3535.363525          a photo of a person regional orized.\n",
       "109  4481.204102          a photo of a person landmark orized.\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from domino.emb.clip import CELEBA_PHRASE_TEMPLATES\n",
    "templates = CELEBA_PHRASE_TEMPLATES\n",
    "words = word_dp[\"word\"][:10]\n",
    "input_phrases = [\n",
    "    template.format(word) for word in words for template in templates\n",
    "]\n",
    "inputs = tokenizer(input_phrases, return_tensors=\"pt\", padding=True).to(device)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "outputs = model(**inputs) # shape=(num_sents, num_tokens_in_sent, size_vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "probs = torch.softmax(outputs.logits, dim=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "k = 2\n",
    "top_k_out = probs.topk(k=k, dim=-1)\n",
    "PAD_TOKEN_ID = 103\n",
    "\n",
    "output_phrases = []\n",
    "output_probs = []\n",
    "for sent_idx in range(probs.shape[0]):\n",
    "    mask_mask = input_ids[sent_idx] == PAD_TOKEN_ID\n",
    "    token_ids = top_k_out.indices[sent_idx, mask_mask]\n",
    "    token_probs = top_k_out.values[sent_idx, mask_mask]\n",
    "    for local_idxs in product(np.arange(k), repeat=mask_mask.sum()):\n",
    "        output_ids = torch.clone(input_ids[sent_idx])\n",
    "        output_ids[mask_mask] = token_ids[torch.arange(mask_mask.sum()), local_idxs] \n",
    "        output_phrases.append(tokenizer.decode(output_ids, skip_special_tokens=True))\n",
    "        output_probs.append(token_probs[torch.arange(mask_mask.sum()), local_idxs].mean().cpu().detach().numpy())\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"prob\": output_probs, \"phrase\": output_phrases})\n",
    "df.sort_values(\"prob\", ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>a photo of a person the.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.49835655</td>\n",
       "      <td>a photo of a person dressed as a child.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.49652216</td>\n",
       "      <td>a photo of a person as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.48906392</td>\n",
       "      <td>a photo of a person dressed as a model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.3766427</td>\n",
       "      <td>a photo of a person dressed dressed as a person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.3659794</td>\n",
       "      <td>a photo of a person dressed as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>nan</td>\n",
       "      <td>a photo of a person as.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.37600285</td>\n",
       "      <td>a photo of a person sitting on it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.3701461</td>\n",
       "      <td>a photo of a person was placed on the wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.36785626</td>\n",
       "      <td>a photo of a person was sitting on the wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.361984</td>\n",
       "      <td>a photo of a person sitting on the wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.34724897</td>\n",
       "      <td>a photo of a person was placed on the screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>nan</td>\n",
       "      <td>a photo of a person on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.3861788</td>\n",
       "      <td>a photo of a person dressed dressed as a child.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>nan</td>\n",
       "      <td>a photo of a person for.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.7142288</td>\n",
       "      <td>a photo of a person that is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.539133</td>\n",
       "      <td>a photo of a person who is taken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.44311094</td>\n",
       "      <td>a photo of a person who that is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.4155189</td>\n",
       "      <td>a photo of a person who is shown.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.37254715</td>\n",
       "      <td>a photo of a person posing as a model.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob                                            phrase\n",
       "0           nan                          a photo of a person the.\n",
       "454  0.49835655           a photo of a person dressed as a child.\n",
       "442  0.49652216                      a photo of a person as well.\n",
       "455  0.48906392           a photo of a person dressed as a model.\n",
       "475   0.3766427  a photo of a person dressed dressed as a person.\n",
       "450   0.3659794              a photo of a person dressed as well.\n",
       "441         nan                           a photo of a person as.\n",
       "401  0.37600285                a photo of a person sitting on it.\n",
       "425   0.3701461       a photo of a person was placed on the wall.\n",
       "429  0.36785626      a photo of a person was sitting on the wall.\n",
       "405    0.361984          a photo of a person sitting on the wall.\n",
       "426  0.34724897     a photo of a person was placed on the screen.\n",
       "392         nan                           a photo of a person on.\n",
       "474   0.3861788   a photo of a person dressed dressed as a child.\n",
       "343         nan                          a photo of a person for.\n",
       "301   0.7142288                      a photo of a person that is.\n",
       "303    0.539133                 a photo of a person who is taken.\n",
       "315  0.44311094                  a photo of a person who that is.\n",
       "304   0.4155189                 a photo of a person who is shown.\n",
       "459  0.37254715            a photo of a person posing as a model."
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "local_idxs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from itertools import product\n",
    "x[np.array(list(product(np.arange(k), repeat=4)))]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8084/4097236563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[[4.8436e-02, 1.8082e-02],\n",
       "         [9.9977e-01, 5.0052e-05],\n",
       "         [6.9458e-01, 2.9586e-01],\n",
       "         ...,\n",
       "         [9.9806e-01, 1.2715e-03],\n",
       "         [9.9830e-01, 1.1925e-03],\n",
       "         [9.9728e-01, 2.0902e-03]],\n",
       "\n",
       "        [[3.0408e-02, 1.0726e-02],\n",
       "         [1.0000e+00, 6.8612e-08],\n",
       "         [9.4834e-01, 5.1066e-02],\n",
       "         ...,\n",
       "         [9.7172e-01, 4.2474e-03],\n",
       "         [3.1486e-01, 7.4373e-02],\n",
       "         [1.6941e-01, 7.4333e-02]],\n",
       "\n",
       "        [[2.8445e-02, 1.0210e-02],\n",
       "         [1.0000e+00, 9.6760e-08],\n",
       "         [9.6188e-01, 3.7719e-02],\n",
       "         ...,\n",
       "         [9.9834e-01, 8.7955e-04],\n",
       "         [3.1594e-01, 6.6326e-02],\n",
       "         [5.5921e-01, 1.2219e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.3498e-02, 1.1045e-02],\n",
       "         [1.0000e+00, 1.3866e-07],\n",
       "         [9.6421e-01, 3.5359e-02],\n",
       "         ...,\n",
       "         [7.2595e-01, 2.3038e-01],\n",
       "         [9.7169e-01, 5.1077e-03],\n",
       "         [8.5109e-01, 4.2533e-02]],\n",
       "\n",
       "        [[2.7845e-02, 8.7831e-03],\n",
       "         [1.0000e+00, 6.0285e-07],\n",
       "         [9.8258e-01, 1.7109e-02],\n",
       "         ...,\n",
       "         [9.9215e-01, 2.4696e-03],\n",
       "         [1.7410e-01, 1.2963e-01],\n",
       "         [2.3544e-01, 2.1064e-01]],\n",
       "\n",
       "        [[2.5052e-02, 9.2082e-03],\n",
       "         [1.0000e+00, 1.3993e-07],\n",
       "         [9.8400e-01, 1.5562e-02],\n",
       "         ...,\n",
       "         [7.4046e-02, 3.5902e-02],\n",
       "         [9.7614e-01, 1.4365e-02],\n",
       "         [9.7498e-01, 1.5100e-02]]], device='cuda:0', grad_fn=<TopkBackward>),\n",
       "indices=tensor([[[1012, 1996],\n",
       "         [1037, 1996],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [1012, 1025],\n",
       "         [1012, 1025],\n",
       "         [1012, 1025]],\n",
       "\n",
       "        [[1012, 1996],\n",
       "         [1037, 2178],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [1037, 1996],\n",
       "         [2030, 2823],\n",
       "         [2030, 1037]],\n",
       "\n",
       "        [[1012, 1996],\n",
       "         [1037, 1996],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [1012, 1025],\n",
       "         [2030, 1998],\n",
       "         [2030, 1998]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1012, 1996],\n",
       "         [1037, 2019],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [1012, 1996],\n",
       "         [1012, 1025],\n",
       "         [1012, 2030]],\n",
       "\n",
       "        [[1012, 1996],\n",
       "         [1037, 2178],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [1012, 1025],\n",
       "         [2009, 2003],\n",
       "         [2030, 1998]],\n",
       "\n",
       "        [[1012, 1996],\n",
       "         [1037, 1996],\n",
       "         [6302, 3861],\n",
       "         ...,\n",
       "         [2775, 2711],\n",
       "         [1012, 1996],\n",
       "         [1012, 1996]]], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('domino': conda)"
  },
  "interpreter": {
   "hash": "0d937a63d09daec3f9548a5c769ccb20edb9c2c1ae2375686b21850f577713d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}