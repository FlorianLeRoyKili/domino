{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from domino.slices import collect_settings\n",
    "from domino.slices.celeba import CelebASliceBuilder\n",
    "from domino.evaluate import run_sdm, score_sdms\n",
    "from domino.train import train_settings\n",
    "import numpy as np\n",
    "import terra"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sabri/code/meerkat/meerkat/nn/__init__.py:7: ExperimentalWarning: The `meerkat.nn` module is experimental and has limited test coverage. Proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "score_df = score_sdms.out().load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "score_df.iloc[score_df.reset_index().groupby([\"target_name\", \"slice_name\", \"slice_idx\"])['precision_at_10'].idxmax().astype(int)]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_slice_idx</th>\n",
       "      <th>slice_idx</th>\n",
       "      <th>auroc</th>\n",
       "      <th>precision_at_10</th>\n",
       "      <th>precision_at_25</th>\n",
       "      <th>precision_at_100</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>recall_at_100</th>\n",
       "      <th>recall_at_200</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>target_name</th>\n",
       "      <th>run_sdm_run_id</th>\n",
       "      <th>slice_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743448</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>0.156923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>bangs</td>\n",
       "      <td>16615</td>\n",
       "      <td>bangs=0_blond_hair=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.131902</td>\n",
       "      <td>0.239264</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.285276</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>bangs</td>\n",
       "      <td>16617</td>\n",
       "      <td>bangs=1_blond_hair=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.057263</td>\n",
       "      <td>0.087989</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.219712</td>\n",
       "      <td>black_hair</td>\n",
       "      <td>16681</td>\n",
       "      <td>black_hair=0_wearing_earrings=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.145390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>black_hair</td>\n",
       "      <td>16614</td>\n",
       "      <td>black_hair=1_wearing_earrings=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.062417</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>0.188579</td>\n",
       "      <td>0.277886</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16708</td>\n",
       "      <td>blond_hair=0_bangs=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756926</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.091935</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16719</td>\n",
       "      <td>blond_hair=0_wearing_earrings=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16566</td>\n",
       "      <td>blond_hair=0_wearing_necklace=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>0.217654</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16707</td>\n",
       "      <td>blond_hair=1_bangs=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.066570</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.238784</td>\n",
       "      <td>0.470333</td>\n",
       "      <td>0.327952</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16718</td>\n",
       "      <td>blond_hair=1_wearing_earrings=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.089912</td>\n",
       "      <td>0.153509</td>\n",
       "      <td>0.287281</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>16564</td>\n",
       "      <td>blond_hair=1_wearing_necklace=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799884</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.028256</td>\n",
       "      <td>goatee</td>\n",
       "      <td>16630</td>\n",
       "      <td>goatee=0_mustache=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872129</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.256024</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>goatee</td>\n",
       "      <td>16634</td>\n",
       "      <td>goatee=0_wearing_necktie=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.404545</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>goatee</td>\n",
       "      <td>16628</td>\n",
       "      <td>goatee=1_mustache=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.951031</td>\n",
       "      <td>goatee</td>\n",
       "      <td>16636</td>\n",
       "      <td>goatee=1_wearing_necktie=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.048040</td>\n",
       "      <td>0.093552</td>\n",
       "      <td>0.533502</td>\n",
       "      <td>0.694079</td>\n",
       "      <td>male</td>\n",
       "      <td>16601</td>\n",
       "      <td>male=0_smiling=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886633</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.043391</td>\n",
       "      <td>0.082109</td>\n",
       "      <td>0.227637</td>\n",
       "      <td>0.586919</td>\n",
       "      <td>male</td>\n",
       "      <td>16600</td>\n",
       "      <td>male=1_smiling=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864782</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.099567</td>\n",
       "      <td>0.186147</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>mustache</td>\n",
       "      <td>16607</td>\n",
       "      <td>mustache=0_goatee=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560165</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.282927</td>\n",
       "      <td>0.122881</td>\n",
       "      <td>mustache</td>\n",
       "      <td>16716</td>\n",
       "      <td>mustache=0_wearing_hat=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.822511</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.965217</td>\n",
       "      <td>mustache</td>\n",
       "      <td>16608</td>\n",
       "      <td>mustache=1_goatee=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.223256</td>\n",
       "      <td>0.432558</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>0.376744</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>mustache</td>\n",
       "      <td>16688</td>\n",
       "      <td>mustache=1_wearing_hat=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636206</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.049458</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.589431</td>\n",
       "      <td>0.599586</td>\n",
       "      <td>smiling</td>\n",
       "      <td>16712</td>\n",
       "      <td>smiling=0_male=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853923</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.057903</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.201896</td>\n",
       "      <td>smiling</td>\n",
       "      <td>16632</td>\n",
       "      <td>smiling=0_wearing_lipstick=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>0.129450</td>\n",
       "      <td>0.739159</td>\n",
       "      <td>0.925446</td>\n",
       "      <td>smiling</td>\n",
       "      <td>16712</td>\n",
       "      <td>smiling=1_male=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.323577</td>\n",
       "      <td>0.164228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>smiling</td>\n",
       "      <td>16632</td>\n",
       "      <td>smiling=1_wearing_lipstick=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610043</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.029151</td>\n",
       "      <td>0.045627</td>\n",
       "      <td>0.847909</td>\n",
       "      <td>0.165104</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16720</td>\n",
       "      <td>wearing_earrings=0_black_hair=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827317</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>0.144869</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16738</td>\n",
       "      <td>wearing_earrings=0_blond_hair=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568757</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>0.057793</td>\n",
       "      <td>0.458844</td>\n",
       "      <td>0.088783</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16736</td>\n",
       "      <td>wearing_earrings=0_brown_hair=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.057618</td>\n",
       "      <td>0.111396</td>\n",
       "      <td>0.212548</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16715</td>\n",
       "      <td>wearing_earrings=1_black_hair=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.306418</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.595486</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16743</td>\n",
       "      <td>wearing_earrings=1_blond_hair=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.064348</td>\n",
       "      <td>0.128696</td>\n",
       "      <td>0.224348</td>\n",
       "      <td>0.366957</td>\n",
       "      <td>0.542416</td>\n",
       "      <td>wearing_earrings</td>\n",
       "      <td>16742</td>\n",
       "      <td>wearing_earrings=1_brown_hair=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412368</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>16734</td>\n",
       "      <td>wearing_hat=0_eyeglasses=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776381</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.097701</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>16568</td>\n",
       "      <td>wearing_hat=0_goatee=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989245</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535519</td>\n",
       "      <td>0.644809</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.576132</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>16731</td>\n",
       "      <td>wearing_hat=1_eyeglasses=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.191011</td>\n",
       "      <td>0.342697</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>16583</td>\n",
       "      <td>wearing_hat=1_goatee=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.143357</td>\n",
       "      <td>0.660839</td>\n",
       "      <td>0.103732</td>\n",
       "      <td>wearing_lipstick</td>\n",
       "      <td>16656</td>\n",
       "      <td>wearing_lipstick=0_smiling=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.231023</td>\n",
       "      <td>0.402640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098154</td>\n",
       "      <td>wearing_lipstick</td>\n",
       "      <td>16657</td>\n",
       "      <td>wearing_lipstick=1_smiling=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781806</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.093677</td>\n",
       "      <td>0.168618</td>\n",
       "      <td>0.255269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>16606</td>\n",
       "      <td>wearing_necklace=0_bangs=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.161172</td>\n",
       "      <td>0.304029</td>\n",
       "      <td>0.498168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>16728</td>\n",
       "      <td>wearing_necklace=0_blond_hair=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971431</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0.150485</td>\n",
       "      <td>0.288835</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.559611</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>16604</td>\n",
       "      <td>wearing_necklace=1_bangs=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.151625</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>16728</td>\n",
       "      <td>wearing_necklace=1_blond_hair=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737463</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.141844</td>\n",
       "      <td>0.184397</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.546099</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>wearing_necktie</td>\n",
       "      <td>16545</td>\n",
       "      <td>wearing_necktie=0_eyeglasses=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.309211</td>\n",
       "      <td>0.572368</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>wearing_necktie</td>\n",
       "      <td>16534</td>\n",
       "      <td>wearing_necktie=1_eyeglasses=0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_slice_idx  slice_idx     auroc  precision_at_10  precision_at_25  \\\n",
       "1481               1          0  0.743448              0.3             0.40   \n",
       "1478               3          1  0.975295              1.0             1.00   \n",
       "2371               1          0  0.689536              1.0             0.68   \n",
       "1516               1          1  0.964863              1.0             1.00   \n",
       "3044               4          0  0.695051              0.8             0.68   \n",
       "3160               0          0  0.756926              0.6             0.52   \n",
       "654                4          0  0.667694              0.4             0.28   \n",
       "3035               0          1  0.984851              1.0             0.92   \n",
       "3145               0          1  0.884068              1.0             1.00   \n",
       "636                1          1  0.969584              1.0             0.88   \n",
       "1610               0          0  0.799884              0.4             0.28   \n",
       "1662               2          0  0.872129              0.5             0.48   \n",
       "1595               0          1  0.993425              0.9             0.80   \n",
       "1676               1          1  0.998267              1.0             0.96   \n",
       "1304               4          0  0.844299              1.0             0.88   \n",
       "1315               0          1  0.886633              0.8             0.76   \n",
       "1383               3          0  0.864782              0.5             0.36   \n",
       "2921               1          0  0.560165              0.6             0.36   \n",
       "1396               1          1  0.999111              1.0             0.96   \n",
       "2437               2          1  0.996550              1.0             1.00   \n",
       "3062               2          0  0.636206              0.8             0.84   \n",
       "1631               1          0  0.853923              0.9             0.80   \n",
       "3068               3          1  0.890555              1.0             1.00   \n",
       "1637               2          1  0.977597              1.0             1.00   \n",
       "3120               0          0  0.610043              0.5             0.36   \n",
       "3390               0          0  0.827317              0.8             0.60   \n",
       "3343               3          0  0.568757              0.3             0.24   \n",
       "3115               0          1  0.969996              1.0             0.88   \n",
       "3417               2          1  0.975851              1.0             0.88   \n",
       "3368               3          1  0.955956              1.0             0.80   \n",
       "3292               2          0  0.412368              0.2             0.08   \n",
       "681                1          0  0.776381              0.5             0.32   \n",
       "3275               0          1  0.989245              0.7             0.48   \n",
       "1015               0          1  0.989493              1.0             0.88   \n",
       "2040               0          0  0.788364              0.8             0.60   \n",
       "2059               4          1  0.913000              1.0             0.92   \n",
       "1374               4          0  0.781806              0.9             0.80   \n",
       "3233               3          0  0.902610              1.0             0.96   \n",
       "1355               0          1  0.971431              0.9             0.84   \n",
       "3235               0          1  0.973461              1.0             0.88   \n",
       "374                4          0  0.737463              0.8             0.56   \n",
       "66                 1          1  0.997183              1.0             0.92   \n",
       "\n",
       "      precision_at_100  recall_at_50  recall_at_100  recall_at_200    recall  \\\n",
       "1481              0.28      0.046154       0.086154       0.156923  1.000000   \n",
       "1478              0.78      0.131902       0.239264       0.429448  0.285276   \n",
       "2371              0.41      0.034916       0.057263       0.087989  0.787709   \n",
       "1516              1.00      0.088652       0.177305       0.329787  0.145390   \n",
       "3044              0.47      0.039841       0.062417       0.110226  0.188579   \n",
       "3160              0.30      0.030645       0.048387       0.091935  0.354839   \n",
       "654               0.16      0.028796       0.041885       0.073298  0.013089   \n",
       "3035              0.92      0.055623       0.111245       0.217654  0.055623   \n",
       "3145              0.85      0.066570       0.123010       0.238784  0.470333   \n",
       "636               0.70      0.089912       0.153509       0.287281  0.114035   \n",
       "1610              0.25      0.083333       0.148810       0.267857  0.976190   \n",
       "1662              0.50      0.072289       0.150602       0.256024  0.204819   \n",
       "1595              0.74      0.172727       0.336364       0.659091  0.404545   \n",
       "1676              0.96      0.000000       0.322500       0.477500  0.922500   \n",
       "1304              0.76      0.026549       0.048040       0.093552  0.533502   \n",
       "1315              0.65      0.022697       0.043391       0.082109  0.227637   \n",
       "1383              0.23      0.051948       0.099567       0.186147  0.350649   \n",
       "2921              0.23      0.078049       0.112195       0.146341  0.282927   \n",
       "1396              0.96      0.207792       0.415584       0.822511  0.480519   \n",
       "2437              0.93      0.223256       0.432558       0.753488  0.376744   \n",
       "3062              0.73      0.025745       0.049458       0.081301  0.589431   \n",
       "1631              0.71      0.057903       0.111111       0.169014  1.000000   \n",
       "3068              1.00      0.032362       0.064725       0.129450  0.739159   \n",
       "1637              1.00      0.081301       0.162602       0.323577  0.164228   \n",
       "3120              0.23      0.016477       0.029151       0.045627  0.847909   \n",
       "3390              0.58      0.056338       0.116700       0.213280  0.144869   \n",
       "3343              0.22      0.021016       0.038529       0.057793  0.458844   \n",
       "3115              0.87      0.057618       0.111396       0.212548  0.125480   \n",
       "3417              0.77      0.076605       0.159420       0.306418  0.710145   \n",
       "3368              0.74      0.064348       0.128696       0.224348  0.366957   \n",
       "3292              0.03      0.012579       0.018868       0.018868  0.937107   \n",
       "681               0.17      0.074713       0.097701       0.126437  0.063218   \n",
       "3275              0.51      0.000000       0.535519       0.644809  0.765027   \n",
       "1015              0.61      0.191011       0.342697       0.646067  0.000000   \n",
       "2040              0.27      0.069930       0.094406       0.143357  0.660839   \n",
       "2059              0.70      0.118812       0.231023       0.402640  1.000000   \n",
       "1374              0.72      0.093677       0.168618       0.255269  1.000000   \n",
       "3233              0.83      0.161172       0.304029       0.498168  1.000000   \n",
       "1355              0.62      0.082524       0.150485       0.288835  0.558252   \n",
       "3235              0.75      0.151625       0.270758       0.462094  0.018051   \n",
       "374               0.26      0.141844       0.184397       0.255319  0.546099   \n",
       "66                0.87      0.309211       0.572368       0.960526  0.927632   \n",
       "\n",
       "      precision       target_name  run_sdm_run_id  \\\n",
       "1481   0.061740             bangs           16615   \n",
       "1478   0.550296             bangs           16617   \n",
       "2371   0.219712        black_hair           16681   \n",
       "1516   1.000000        black_hair           16614   \n",
       "3044   0.277886        blond_hair           16708   \n",
       "3160   0.305556        blond_hair           16719   \n",
       "654    0.102041        blond_hair           16566   \n",
       "3035   0.920000        blond_hair           16707   \n",
       "3145   0.327952        blond_hair           16718   \n",
       "636    0.712329        blond_hair           16564   \n",
       "1610   0.028256            goatee           16630   \n",
       "1662   0.441558            goatee           16634   \n",
       "1595   0.741667            goatee           16628   \n",
       "1676   0.951031            goatee           16636   \n",
       "1304   0.694079              male           16601   \n",
       "1315   0.586919              male           16600   \n",
       "1383   0.097006          mustache           16607   \n",
       "2921   0.122881          mustache           16716   \n",
       "1396   0.965217          mustache           16608   \n",
       "2437   0.941860          mustache           16688   \n",
       "3062   0.599586           smiling           16712   \n",
       "1631   0.201896           smiling           16632   \n",
       "3068   0.925446           smiling           16712   \n",
       "1637   1.000000           smiling           16632   \n",
       "3120   0.165104  wearing_earrings           16720   \n",
       "3390   0.637168  wearing_earrings           16738   \n",
       "3343   0.088783  wearing_earrings           16736   \n",
       "3115   0.790323  wearing_earrings           16715   \n",
       "3417   0.595486  wearing_earrings           16743   \n",
       "3368   0.542416  wearing_earrings           16742   \n",
       "3292   0.025743       wearing_hat           16734   \n",
       "681    0.192982       wearing_hat           16568   \n",
       "3275   0.576132       wearing_hat           16731   \n",
       "1015   0.000000       wearing_hat           16583   \n",
       "2040   0.103732  wearing_lipstick           16656   \n",
       "2059   0.098154  wearing_lipstick           16657   \n",
       "1374   0.078652  wearing_necklace           16606   \n",
       "3233   0.049430  wearing_necklace           16728   \n",
       "1355   0.559611  wearing_necklace           16604   \n",
       "3235   0.714286  wearing_necklace           16728   \n",
       "374    0.017945   wearing_necktie           16545   \n",
       "66     0.750000   wearing_necktie           16534   \n",
       "\n",
       "                           slice_name  \n",
       "1481             bangs=0_blond_hair=1  \n",
       "1478             bangs=1_blond_hair=0  \n",
       "2371  black_hair=0_wearing_earrings=1  \n",
       "1516  black_hair=1_wearing_earrings=0  \n",
       "3044             blond_hair=0_bangs=1  \n",
       "3160  blond_hair=0_wearing_earrings=1  \n",
       "654   blond_hair=0_wearing_necklace=1  \n",
       "3035             blond_hair=1_bangs=0  \n",
       "3145  blond_hair=1_wearing_earrings=0  \n",
       "636   blond_hair=1_wearing_necklace=0  \n",
       "1610              goatee=0_mustache=1  \n",
       "1662       goatee=0_wearing_necktie=1  \n",
       "1595              goatee=1_mustache=0  \n",
       "1676       goatee=1_wearing_necktie=0  \n",
       "1304                 male=0_smiling=1  \n",
       "1315                 male=1_smiling=0  \n",
       "1383              mustache=0_goatee=1  \n",
       "2921         mustache=0_wearing_hat=1  \n",
       "1396              mustache=1_goatee=0  \n",
       "2437         mustache=1_wearing_hat=0  \n",
       "3062                 smiling=0_male=1  \n",
       "1631     smiling=0_wearing_lipstick=1  \n",
       "3068                 smiling=1_male=0  \n",
       "1637     smiling=1_wearing_lipstick=0  \n",
       "3120  wearing_earrings=0_black_hair=1  \n",
       "3390  wearing_earrings=0_blond_hair=1  \n",
       "3343  wearing_earrings=0_brown_hair=1  \n",
       "3115  wearing_earrings=1_black_hair=0  \n",
       "3417  wearing_earrings=1_blond_hair=0  \n",
       "3368  wearing_earrings=1_brown_hair=0  \n",
       "3292       wearing_hat=0_eyeglasses=1  \n",
       "681            wearing_hat=0_goatee=1  \n",
       "3275       wearing_hat=1_eyeglasses=0  \n",
       "1015           wearing_hat=1_goatee=0  \n",
       "2040     wearing_lipstick=0_smiling=1  \n",
       "2059     wearing_lipstick=1_smiling=0  \n",
       "1374       wearing_necklace=0_bangs=1  \n",
       "3233  wearing_necklace=0_blond_hair=1  \n",
       "1355       wearing_necklace=1_bangs=0  \n",
       "3235  wearing_necklace=1_blond_hair=0  \n",
       "374    wearing_necktie=0_eyeglasses=1  \n",
       "66     wearing_necktie=1_eyeglasses=0  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "inp = run_sdm.inp(run_id=16681, load=True)\n",
    "data_dp, emb_dp = inp[\"data_dp\"], inp[\"emb_dp\"]\n",
    "\n",
    "data_dp = data_dp.lz[data_dp[\"split\"].isin([\"valid\", \"test\"])].merge(\n",
    "    emb_dp[[\"image_id\", \"emb\"]], on=\"image_id\"\n",
    ")\n",
    "slice_idx = 0\n",
    "inp[\"slice_names\"][slice_idx]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'black_hair=0_wearing_earrings=1'"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "from domino.metrics import compute_model_metrics\n",
    "compute_model_metrics(data_dp, num_iter=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sabri/code/domino/domino/metrics.py:198: RuntimeWarning: Mean of empty slice.\n",
      "  bs_sample_estimates = bs_samples.mean(axis=0)\n",
      "/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/numpy/core/_methods.py:153: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'overall': {'auroc': {'mean': 0.9527946965416821,\n",
       "   'lower': 0.950575410222608,\n",
       "   'upper': 0.9563088730878351},\n",
       "  'recall': {'mean': tensor(0.8679),\n",
       "   'lower': 0.8591553062200548,\n",
       "   'upper': 0.881264153122902},\n",
       "  'precision': {'mean': 0.0, 'lower': 0.0, 'upper': 0.0}},\n",
       " 'in_slice_0': {'auroc': nan,\n",
       "  'recall': {'mean': tensor(nan), 'lower': nan, 'upper': nan},\n",
       "  'precision': {'mean': 0.0, 'lower': 0.0, 'upper': 0.0}},\n",
       " 'in_slice_1': {'auroc': nan,\n",
       "  'recall': {'mean': tensor(0.8510),\n",
       "   'lower': 0.8311215907335281,\n",
       "   'upper': 0.8776112973690033},\n",
       "  'precision': {'mean': 1.0, 'lower': 1.0, 'upper': 1.0}},\n",
       " 'out_slice': {'auroc': {'mean': 0.9662526073120323,\n",
       "   'lower': 0.9625685562675699,\n",
       "   'upper': 0.9713047084847526},\n",
       "  'recall': {'mean': tensor(0.9010),\n",
       "   'lower': 0.8790268629789353,\n",
       "   'upper': 0.9132550299167633},\n",
       "  'precision': {'mean': 0.0, 'lower': 0.0, 'upper': 0.0}}}"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from domino.sdm import MixtureModelSDM, SpotlightSDM\n",
    "sdm = MixtureModelSDM(\n",
    "    n_slices=5, \n",
    "    n_clusters=25, \n",
    "    weight_y_log_likelihood=10, \n",
    "    init_params=\"error\",\n",
    "    emb=\"emb\",\n",
    "    pca_components=128 \n",
    ")\n",
    "\n",
    "sdm.fit(data_dp.lz[data_dp[\"split\"] == \"valid\"])\n",
    "dp = sdm.transform(data_dp.lz[data_dp[\"split\"] == \"test\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 94%|█████████▍| 94/100 [00:04<00:00, 22.61it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "from domino.metrics import compute_sdm_metrics\n",
    "\n",
    "metrics_df = compute_sdm_metrics(dp)\n",
    "metrics_df[metrics_df[\"slice_idx\"] == slice_idx].sort_values(\n",
    "    by=\"auroc\", ascending=False\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_slice_idx</th>\n",
       "      <th>slice_idx</th>\n",
       "      <th>auroc</th>\n",
       "      <th>precision_at_10</th>\n",
       "      <th>precision_at_25</th>\n",
       "      <th>precision_at_100</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>recall_at_100</th>\n",
       "      <th>recall_at_200</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756320</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.051676</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>0.311453</td>\n",
       "      <td>0.191745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724198</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.026536</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.081006</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.138462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640689</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>0.074022</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>0.146667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.094057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_slice_idx  slice_idx     auroc  precision_at_10  precision_at_25  \\\n",
       "3               3          0  0.756320              0.6             0.40   \n",
       "0               0          0  0.724198              0.5             0.44   \n",
       "4               4          0  0.647392              0.3             0.20   \n",
       "1               1          0  0.640689              0.3             0.36   \n",
       "2               2          0  0.621842              0.0             0.00   \n",
       "\n",
       "   precision_at_100  recall_at_50  recall_at_100  recall_at_200    recall  \\\n",
       "3              0.37      0.033520       0.051676       0.096369  0.311453   \n",
       "0              0.36      0.026536       0.050279       0.081006  0.002793   \n",
       "4              0.25      0.016760       0.034916       0.044693  0.025140   \n",
       "1              0.33      0.025140       0.046089       0.074022  0.046089   \n",
       "2              0.07      0.001397       0.009777       0.033520  0.614525   \n",
       "\n",
       "   precision  \n",
       "3   0.191745  \n",
       "0   0.090909  \n",
       "4   0.138462  \n",
       "1   0.146667  \n",
       "2   0.094057  "
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "pred_slice_idx = 3\n",
    "words_dp = words_dp.view()\n",
    "slice_proto = (\n",
    "    np.dot(dp[\"pred_slices\"].T, dp[\"emb\"])\n",
    "    / dp[\"pred_slices\"].sum(axis=0, keepdims=True).T\n",
    ")\n",
    "pred_slice = dp[\"pred_slices\"][:, pred_slice_idx]\n",
    "slice_proto = dp.lz[pred_slice.argsort()[-40:]][\"emb\"].mean(axis=0)\n",
    "#slice_proto = dp.lz[dp[\"probs\"].argsort()[-25:]][\"emb\"].mean(axis=0)\n",
    "\n",
    "\n",
    "ref_proto = dp[\"emb\"][dp[\"target\"] == 0].data.mean(axis=0)\n",
    "\n",
    "words_dp[\"pred_slices\"] = np.dot(\n",
    "    words_dp[\"emb\"].data, (slice_proto - ref_proto).T\n",
    ")\n",
    "expl_dp = words_dp[[\"word\", \"pred_slices\", \"frequency\"]]\n",
    "expl_dp.lz[(-expl_dp[\"pred_slices\"]).argsort()[:10]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>pred_slices (NumpyArrayColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marina</td>\n",
       "      <td>2.080078</td>\n",
       "      <td>22949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actress</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>153682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chola</td>\n",
       "      <td>2.039062</td>\n",
       "      <td>5748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>1.837891</td>\n",
       "      <td>5665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rouge</td>\n",
       "      <td>1.730469</td>\n",
       "      <td>18595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rani</td>\n",
       "      <td>1.677734</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amy</td>\n",
       "      <td>1.623047</td>\n",
       "      <td>29329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>goddess</td>\n",
       "      <td>1.615234</td>\n",
       "      <td>31750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>periphery</td>\n",
       "      <td>1.613281</td>\n",
       "      <td>7138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lea</td>\n",
       "      <td>1.459961</td>\n",
       "      <td>9629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 10, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "expl_dp.lz[expl_dp[\"word\"]==\"earrings\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>pred_slices (NumpyArrayColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 0, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wordnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "\n",
    "dp.lz[dp[\"pred_slices\"].data[:, pred_slice_idx].argsort()[-10:]][[\"image\", \"target\", \"correlate\"]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image (ImageColumn)</th>\n",
       "      <th>target (NumpyArrayColumn)</th>\n",
       "      <th>correlate (NumpyArrayColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAGkDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwKr+h/wDIf03/AK+ov/QxVCr+h/8AIf03/r6i/wDQxUmjPqxOv41ciqogOfxq3EOKlDHJ/wAfMn0Wq9p/x8Xn/Xb+gqyqETOxHBAxVaz5nuzgj993GM8Ck90UtmaEdc0v/Iyah/19Ww/SuhM8MGzzpUTedq7jjcfQVg28Ek+uXc8QDxSXMLoykEMqjBI+lV2Jhu2c74r/AOR0b/tn/Kuw8M8Af9ecH/s1ch4mRpfHBRBuZmQAA9Tiuw0Mi0mjguP3Ur2sKor8FiAcge4rjw/8Wfqepjv93pL+7+pw3jrnxTN/1yT+Vbq8fCVfcj/0ZWB43dW8U3OCPlRQfY4rdWRH+EyhGBKsA2D0O+uZfHV9GenP/dcOvOJz+q/8gDRR/sS/+hVjVtasMaHog9YZCPpvrFrlrfF8l+R6mD/h/N/mzxir+h/8jBpv/X3F/wChiqFX9C/5GHTP+vuL/wBDFfQHwbPrNVw1WAdqZwTgZwOpqEfeP1qcEKMnpUjGG7iS3jlmPkhyABJwcntWTrPivRtChllv7oR+WQNgGWc9flHeuM8f/Ee0s4X0qxiFzduPnEg+SL6ju3tXjN9qNxqF21xdyvPcH+Jm6D0HoKLMLpHomrfFq7nllj0+y2wNIXR5iDIAfT+7/wDXrm28e6/HqRvre48mU5GQM8E5IrlS4JGSzfSnhjjjd9DT5VuPndrGlLrmoT3bXUt7OZ2beWVyvP4V1ehfFLxHpsqCa6GowqQTFdAFh9H6/wA689fO/r+dSISR1+YUcq6A5N6M9i0Bl8Z3d/fNqUFrMzZkimPOGOOPboM1oaTaahPpWq6fb2rTpIw2+UpIJVhnB/WvHLHUpbW7iuoX2zRsDnH8xX0x8NvEdlr2gqsUccN1DhZkQYyf7341y/VYuV07b/ieh/aVTk5Wk9reVjndR8N6xPpOkQxadOXhicOABxlsgGs3/hEdf/6Bdx+Qr25RS0pYCEne7/AqnnVaEeVRXXv1dz4MrQ0LnxFpn/X3F/6GKzs1p+Hfm8T6UPW8i/8AQxXaeVc+tAMMa4/4i+LW8NaEEtWH2+6ykP8AsDu5+ldg2Bu/GvnP4ha7/bni248tybe3/cp6YHU/ialFN2OXLyTSsSxZ5CSzseT6mtmw8NXd6gKJtjbox6t/9aqWmWjXV7DCM7pHx+Hc17RomlIsaqFwigCsa9X2a0N8NQ9o22cPa+Abp0yWAGPSrU3w/lKbhIpIGcV6vHaKVAGOKJbRVU+/SuX6xUep2LDU1ofOuvaDc6VcZkQ+W3Kt/jWXH29R+te3+J9AS/tWXnOCRz0rxi6tmsrySBxyrY6V10avOrHHWo8j02IAuyb/AD0rvPh74gbw54kgl3EQS4jlHbB71w7AMynvWjC+Yo2Bw4OM/wAq1Zzo+yIJFmiWVDlHUMD7GpePWuM+Geuf214Rt97ZmgGxvp2/qK7KqTuiGrOx8F1r+FV3+LdHX1vIv/QhWRW54NXd410VfW8i/wDQhQUfR3jDWRofhW+vQ2JFjKxn/aPAr5njzI25z8ztkk1698Z9RI0yx01TgzS+Y49gOP515HAA06jPQUohJnXeD7LzNQluSOExEn16n+lex6fD5UCLXlPh6aCw05Lr+0IYXZmcRTEbTz+fau90bxKt6RG8SoezpIGVvoa87EqUpX6HqYVxjFR6nXwgnoKdOhI5qnPfyWVt5ix72xkAnrWDP4skSQLqN9a2MbZIVVBY/iazjG6NZSsaV9HlG9xjNeJ+NLT7Prcj7SA+GB9a9gW7sNQjL6fqfndyPMDc+4HSvP8Ax3ZM8aTleclWPp3H8q0o+7OxlW96meeqMn8c1bj/ANSxBPLDFQInUelPUkEoQeRkDNeijy2eu/CLXmsPtkYVnA+YovUg9/wI/WvU/wDhLh/z5Tf98186eENafQ9WeZWChoypzXb/APCwZP8AntHWTbi7GqjzK54NW94I/wCR50Pj/l8j/wDQqwK3vBH/ACPOif8AX7H/AOhVsZHVfFi+afxWkG4/uIgPoT/9bFcPHJ5crgdhitvxvdG78das5zhJjEoz0C8f0rmuS5GeSaEtCXud9pHhaWRUnV42aWLH71d23Pp6V2WmeG49KjRjKxJZcA+uaueGrdYtNid8FggAz9K0dwutVjh3g+VzgnvXmVa05Xj0PYpYaEbS6l+/l85Yogf4awbrQBI9xiOF5p02b36oM9jWvcq0VwOA4XqFYZFaVs8F3tIIPbnrURlKDujWUIzVmef2XgDyLqO4luWhdDkvA2Gb6n/61a3iHT47nRZYNxZgMgnqcV2N7Z+Rb7gBz0rkdVn228nAyAapzlKV2RGjGMbI8ehi/wBKeMjjOMfSq7N5dygI6Eg+tXbx/L1SSQHgsT+dUbwn7VuB43cV6UdjyJ/ES7wrtnODR5iep/Ko5GG8E8dQeKTevqfyp2EnYxK3vBX/ACPGif8AX7H/AOhVgc1veCf+R50T/r9j/wDQqYDvEccieJNQM+RI9xI5yMZy3+fyrGkOJye2a9F+MFp5XiiCZEwsluCSB1IJz/OvOthkxjGaFsS9Ge2aDqiTaTC24gMMZFXlaC7uFCyBZF/iDYYVynw8vImspNPuSPMXlK01tbKDXCZ4ZHgdchFk24Psf6V5k4Wm0e7Qn7SKfkdZBp1qGLShJZf77H5vzqxNGsSrJbMEdP4exHpWY0Hhnl0bUg2VxGZAo9+TWZb2c95d7Ybm6jgHU+ZnP44o5PM1cLK6TXrY6ttZFzbBSfmAwQeorldZdnjcDpit82sNpGep4ABY5JP1rl/FepQaZpsjsw8wjCKOpNTG7lYym7RueZ6m6i+kRedpxVSchpWAHRsflUYmaa5JJz824n1NW4Yg0Su3JLda9SKsrHhyleQ2faMHgAHH6VFvT+8tFzuaAAcfNVXY3rVElDNb/gg/8Vzon/X5H/6FWBXQeBl3eOtEH/T2h/WkUe2/ETRYdV0MSvHmSJuG7gV4NLZTW8jxMh3xkg+49a+o7qBLu3eBxlWHSvNfEnhQQXRKRblkXKuP4TWUm4u5pG0lZ7nltjqkmn3Ec8XUdRnrXq+iz2+u6fBdKQeobPr6V47eQmK4kQjBDHIrofB/ildAkeK4VmtZSCSoyUb1xUV6fPG8dzbC1vZT5ZPQ9ittHtydxAwP9mrrJDAMrgAVzlv4/wBMMBMVzGVI5BGDVK58U/bW22cMsx7bVwv4k8VxqMup6kpp63NrUNQiTdLI4WOMFmJ/nXjHiXW313VGkUnyEOIlPp610PjKa9t9NUXM2JJ2x5Uf3VHue9crYWsCxC7u2Ji5xGn3nx/Ie9dVCCiuY87FVXJ8i2KUPEoA7nFaSt/o8SqcNyfqeaood0pkwFDkkAfw+1TyD9wH54bP511nAPlwBt4KjH41HiP+6KfbEOOW/GrGxf74oA52uk8ADd490Yf9PIP6GubrqPh0N3xA0cf9Nif/AB00ij6UBwc1j+INYtbDTnkaIzysRHFGP43PAGe3Na56GuL8V8w2A9b6L+ZpB1PINf0uW01o2ssgeYr5kmBwCe1YTAo+D34rsvF5/wCK1uP+uY/kK4+b/WL9T/OpT1sW0rXOy8Pg28IYIpBJB4rsLGX5d+AX7A9BXJ6P/wAeS/7xrpbH/Vf8Bb+VediN2eth17qOf8YXttqtsLW2dd0UmXmY4XI6j1/pXLW2j6hcFRFDJGGTqwABz9atXR/0e8/6+ZP5V1dj/q4P+ua11X9lTXKcLSrVXzHMSeFdTihzvDY525rL2OBJBICjdMH1r1Gf/j3Neb3/APyFZf8Ae/rVUKsp7k4ilGHwmZHOYCQRyODUv2/2qvc/8fEn+8agrpOQ/9k=\"></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 10, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plot_df = pd.DataFrame(\n",
    "    {\"probs\": dp[\"probs\"], \"slice\": dp[\"slices\"][:, slice_idx], \"target\": dp[\"target\"]}\n",
    ")\n",
    "sns.histplot(\n",
    "    data=plot_df[plot_df[\"target\"] == 0],\n",
    "    x=\"probs\",\n",
    "    hue=\"slice\",\n",
    "    stat=\"count\",\n",
    "    common_norm=not False,\n",
    "    binwidth=0.1,\n",
    ")\n",
    "plt.yscale(\"log\")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from domino.train import score_settings, train_settings, score_model, train_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "score_settings.out().load()[\"score_model_run_id\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "PandasSeriesColumn(0    15006\n",
       "1 ..., dtype: int64)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "score_dp = score_model.out(15006).load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "mask = score_dp[\"target\"] != score_dp[\"correlate\"]\n",
    "roc_auc_score(score_dp.lz[mask][\"target\"], score_dp.lz[mask][\"probs\"][:, 1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.26252927075972343"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "score_dp[\"probs\"] = score_dp[\"output\"].probabilities()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from domino.train import score_settings, synthetic_score_settings, score_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "type(synthetic_score_settings.out().load())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "meerkat.datapanel.DataPanel"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "score_settings.out()[0].load()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_model_run_id (PandasSeriesColumn)</th>\n",
       "      <th>setting_id (NumpyArrayColumn)</th>\n",
       "      <th>corr (NumpyArrayColumn)</th>\n",
       "      <th>correlate (PandasSeriesColumn)</th>\n",
       "      <th>dataset (PandasSeriesColumn)</th>\n",
       "      <th>n (NumpyArrayColumn)</th>\n",
       "      <th>slice_category (PandasSeriesColumn)</th>\n",
       "      <th>target (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "      <th>parent_run_id (PandasSeriesColumn)</th>\n",
       "      <th>build_setting_run_id (PandasSeriesColumn)</th>\n",
       "      <th>time_this_iter_s (PandasSeriesColumn)</th>\n",
       "      <th>done (PandasSeriesColumn)</th>\n",
       "      <th>timesteps_total (PandasSeriesColumn)</th>\n",
       "      <th>episodes_total (PandasSeriesColumn)</th>\n",
       "      <th>training_iteration (PandasSeriesColumn)</th>\n",
       "      <th>experiment_id (PandasSeriesColumn)</th>\n",
       "      <th>date (PandasSeriesColumn)</th>\n",
       "      <th>timestamp (PandasSeriesColumn)</th>\n",
       "      <th>time_total_s (PandasSeriesColumn)</th>\n",
       "      <th>pid (PandasSeriesColumn)</th>\n",
       "      <th>hostname (PandasSeriesColumn)</th>\n",
       "      <th>node_ip (PandasSeriesColumn)</th>\n",
       "      <th>time_since_restore (PandasSeriesColumn)</th>\n",
       "      <th>timesteps_since_restore (PandasSeriesColumn)</th>\n",
       "      <th>iterations_since_restore (PandasSeriesColumn)</th>\n",
       "      <th>trial_id (PandasSeriesColumn)</th>\n",
       "      <th>config/corr (PandasSeriesColumn)</th>\n",
       "      <th>config/correlate (PandasSeriesColumn)</th>\n",
       "      <th>config/dataset (PandasSeriesColumn)</th>\n",
       "      <th>config/index (PandasSeriesColumn)</th>\n",
       "      <th>config/n (PandasSeriesColumn)</th>\n",
       "      <th>config/setting_id (PandasSeriesColumn)</th>\n",
       "      <th>config/slice_category (PandasSeriesColumn)</th>\n",
       "      <th>config/target (PandasSeriesColumn)</th>\n",
       "      <th>logdir (PandasSeriesColumn)</th>\n",
       "      <th>score_settings_run_id (PandasSeriesColumn)</th>\n",
       "      <th>score_model_run_id (PandasSeriesColumn)</th>\n",
       "      <th>synthetic_preds (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14936</td>\n",
       "      <td>163</td>\n",
       "      <td>0.6</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>celeba</td>\n",
       "      <td>30000</td>\n",
       "      <td>correlation</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>0</td>\n",
       "      <td>14928</td>\n",
       "      <td>14930</td>\n",
       "      <td>1112.037066</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8ef98aebaa294f1f8875ae337af348ea</td>\n",
       "      <td>2021-09-22_12-08-35</td>\n",
       "      <td>1632312515</td>\n",
       "      <td>1112.037066</td>\n",
       "      <td>198</td>\n",
       "      <td>run-script-nf5ts</td>\n",
       "      <td>10.92.1.25</td>\n",
       "      <td>1112.037066</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36c4b_00000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>blond_hair</td>\n",
       "      <td>celeba</td>\n",
       "      <td>163</td>\n",
       "      <td>30000</td>\n",
       "      <td>163</td>\n",
       "      <td>correlation</td>\n",
       "      <td>wearing_necklace</td>\n",
       "      <td>/root/ray_results/_train_model_2021-09-22_11-49-59/_train_model_36c4b_00000_0_config={'corr': 0.6000000000000001, 'correlate': 'blond_hair', 'dataset': 'celeba', 'n': 30000, 'slice__2021-09-22_11-49-59</td>\n",
       "      <td>15044</td>\n",
       "      <td>15045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14933</td>\n",
       "      <td>139</td>\n",
       "      <td>0.8</td>\n",
       "      <td>eyeglasses</td>\n",
       "      <td>celeba</td>\n",
       "      <td>30000</td>\n",
       "      <td>correlation</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>1</td>\n",
       "      <td>14928</td>\n",
       "      <td>14931</td>\n",
       "      <td>1116.230135</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20a0c9441e584990983fc829547b6915</td>\n",
       "      <td>2021-09-22_12-08-39</td>\n",
       "      <td>1632312519</td>\n",
       "      <td>1116.230135</td>\n",
       "      <td>196</td>\n",
       "      <td>run-script-nf5ts</td>\n",
       "      <td>10.92.1.25</td>\n",
       "      <td>1116.230135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36c4b_00001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>eyeglasses</td>\n",
       "      <td>celeba</td>\n",
       "      <td>139</td>\n",
       "      <td>30000</td>\n",
       "      <td>139</td>\n",
       "      <td>correlation</td>\n",
       "      <td>wearing_hat</td>\n",
       "      <td>/root/ray_results/_train_model_2021-09-22_11-49-59/_train_model_36c4b_00001_1_config={'corr': 0.8, 'correlate': 'eyeglasses', 'dataset': 'celeba', 'n': 30000, 'slice_category': 'cor_2021-09-22_11-49-59</td>\n",
       "      <td>15044</td>\n",
       "      <td>15046</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 39)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "score_model.out(15045)[0].load()[\"split\"].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['train', 'valid'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from domino.data.celeba import get_celeba_dp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "sb = CelebASliceBuilder()\n",
    "out = sb.build_rare_setting(\n",
    "    data_dp=get_celeba_dp.out().load(),\n",
    "    target_attrs=[\"wearing_earrings\", \"male\", \"blond_hair\"],\n",
    "    slice_attrs=[\"blond_hair\"],\n",
    "    slice_frac=0.01,\n",
    "    target_frac=0.5,\n",
    "    n=20_000\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "out[\"wearing_earrings\"].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1394"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "np.any(out == 1, axis=0).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7881282730911802"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    " data_dp=get_celeba_dp.out().load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "target_attrs=[\"wearing_earrings\", \"male\", \"blond_hair\"]\n",
    "\n",
    "targets = np.array(\n",
    "            [data_dp[attr] for attr in target_attrs]\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "train_settings.out()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_settings' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2982/4102485765.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_settings' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "from domino.emb.clip import get_wiki_words\n",
    "dp = get_wiki_words(top_k=10_000, eng_only=True).load()\n",
    "(dp[\"word\"] == \"earrings\").any()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "task: get_wiki_words, run_id=16792\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "dp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word (PandasSeriesColumn)</th>\n",
       "      <th>frequency (PandasSeriesColumn)</th>\n",
       "      <th>index (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>151983633.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>71874676.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>62210193.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>62004799.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>43364193.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>het</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>cleric</td>\n",
       "      <td>5531.0</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>unfavorable</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>disperse</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>recurrent</td>\n",
       "      <td>5527.0</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 10000, ncols: 3)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "\"blond\" in dp[\"word\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"A portrait of a person\", max_length=7, num_return_sequences=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': 'A portrait of a person who died'},\n",
       " {'generated_text': \"A portrait of a person's head\"},\n",
       " {'generated_text': 'A portrait of a person holding down'},\n",
       " {'generated_text': 'A portrait of a person who will'},\n",
       " {'generated_text': 'A portrait of a person wearing long'}]"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "hypernyms = []\n",
    "for hypernym in synset.closure(lambda s: s.hypernyms()):\n",
    "    hypernyms.append(\n",
    "        {\n",
    "            \"synset\": synset.name(),\n",
    "            \"hypernym\": hypernym.name(),\n",
    "        }\n",
    "    )\n",
    "hypernyms"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'synset': 'smile.n.01', 'hypernym': 'facial_expression.n.01'},\n",
       " {'synset': 'smile.n.01', 'hypernym': 'gesture.n.02'},\n",
       " {'synset': 'smile.n.01', 'hypernym': 'visual_communication.n.01'},\n",
       " {'synset': 'smile.n.01', 'hypernym': 'communication.n.02'},\n",
       " {'synset': 'smile.n.01', 'hypernym': 'abstraction.n.06'},\n",
       " {'synset': 'smile.n.01', 'hypernym': 'entity.n.01'}]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from transformers import pipeline, set_seed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "unmasker = pipeline(\"\", max_length=30, num_return_sequences=5)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "PipelineException",
     "evalue": "No mask_token (<mask>) found on the input",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2627/3643021087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munmasker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, targets, top_k, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# Fill mask pipeline supports only one ${mask_token} per sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_exactly_one_mask_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36mensure_exactly_one_mask_token\u001b[0;34m(self, masked_index)\u001b[0m\n\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise PipelineException(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPipelineException\u001b[0m: No mask_token (<mask>) found on the input"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "unmasker(f\"A photo of a person .\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'sequence': 'A photo of a person, smiling.',\n",
       "  'score': 0.40710172057151794,\n",
       "  'token': 4,\n",
       "  'token_str': ','},\n",
       " {'sequence': 'A photo of a person while smiling.',\n",
       "  'score': 0.08363543450832367,\n",
       "  'token': 12960,\n",
       "  'token_str': 'while'},\n",
       " {'sequence': 'A photo of a person still smiling.',\n",
       "  'score': 0.0663875937461853,\n",
       "  'token': 7464,\n",
       "  'token_str': 'still'},\n",
       " {'sequence': 'A photo of a person not smiling.',\n",
       "  'score': 0.025921307504177094,\n",
       "  'token': 959,\n",
       "  'token_str': 'not'},\n",
       " {'sequence': 'A photo of a person is smiling.',\n",
       "  'score': 0.0218026302754879,\n",
       "  'token': 83,\n",
       "  'token_str': 'is'}]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "templates = [\n",
    "    \"a photo of a person {}\",\n",
    "    \"a photo of a person {} [MASK]\",\n",
    "    \"a photo of a person {} [MASK] [MASK]\",\n",
    "    \"a photo of a person [MASK] {}\",\n",
    "    \"a photo of a person [MASK] {} [MASK]\",\n",
    "    \"a photo of a person [MASK] {} [MASK][MASK]\",\n",
    "    \"a photo of a person [MASK] [MASK] {}\",\n",
    "    \"a photo of a person [MASK] [MASK] {} [MASK]\",\n",
    "    \"a photo of a person [MASK] [MASK] {} [MASK] [MASK]\",\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel,BertForMaskedLM\n",
    " \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "\n",
    "word = \"smiling\"\n",
    "input_txt = [template.format(word) for template in templates]\n",
    "\n",
    "inputs = tokenizer(input_txt, return_tensors='pt', padding=True).to(0)\n",
    "\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-cased').to(0)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs\n",
    "# sorted_preds, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "# for k in range(10):\n",
    "#     predicted_index = [sorted_idx[i, k if inputs[\"input_ids\"][1, i] == 103 else 0].item() for i in range(0, inputs[\"input_ids\"].shape[-1])]\n",
    "#     predicted_token = [tokenizer.convert_ids_to_tokens([predicted_index[x]])[0] for x in range(1,inputs[\"input_ids\"].shape[-1])]\n",
    "#     print(predicted_token)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d54956d486e2430ab3bd2d770fe1045b"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "676b3317c3b84dd2b16070faf476bd72"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "643e4de3e3104ea6b416f8a9b80bc9c6"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6d5f67a48744bd59bb8ff247e99c686"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=762.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "564419083b6143dea3ab6d78031fff75"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1338740706.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "sorted_preds, sorted_ids = predictions.logits.sort(dim=-1, descending=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "sorted_preds.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([9, 12, 28996])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "input_ids = inputs[\"input_ids\"]\n",
    "for rank in range(10):\n",
    "    curr_ids = sorted_ids[:, :, rank]\n",
    "    curr_ids[input_ids != 103] = input_ids[input_ids != 103]\n",
    "    for sent_idx in range(sorted_ids.shape[0]):\n",
    "\n",
    "        candidate_df.append(\n",
    "            {\n",
    "                \"text\": tokenizer.decode(\n",
    "                    sorted_ids[sent_idx, :, rank], skip_special_tokens=True\n",
    "                ),\n",
    "                \"prob\": sorted_preds[sent_idx, :, rank].mean().cpu().detach().numpy(),\n",
    "            }\n",
    "        )\n",
    "candidate_df = pd.DataFrame(candidate_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "candidate_df.sort_values(\"prob\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>a photo of a person - ; smiling widely and</td>\n",
       "      <td>7.0040717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>a photo of a person standing smiling now and</td>\n",
       "      <td>7.0434494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>a photo of a person with while smiling -</td>\n",
       "      <td>7.0881395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>a photo of a person crying - smiling</td>\n",
       "      <td>7.1516395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>a photo of a person'- smiling eyes \"</td>\n",
       "      <td>7.2351427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a photo of a person, and smiling.</td>\n",
       "      <td>14.271441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a photo of a person, smiling ;</td>\n",
       "      <td>14.699389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a photo of a person smiling broadly ;</td>\n",
       "      <td>14.843798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a photo of a person smiling</td>\n",
       "      <td>15.80104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a photo of a person smiling ;</td>\n",
       "      <td>16.979643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text       prob\n",
       "89    a photo of a person - ; smiling widely and  7.0040717\n",
       "86  a photo of a person standing smiling now and  7.0434494\n",
       "88      a photo of a person with while smiling -  7.0881395\n",
       "87          a photo of a person crying - smiling  7.1516395\n",
       "80          a photo of a person'- smiling eyes \"  7.2351427\n",
       "..                                           ...        ...\n",
       "7              a photo of a person, and smiling.  14.271441\n",
       "4                 a photo of a person, smiling ;  14.699389\n",
       "2          a photo of a person smiling broadly ;  14.843798\n",
       "0                    a photo of a person smiling   15.80104\n",
       "1                  a photo of a person smiling ;  16.979643\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np \n",
    "\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2').to(0)\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "scores = []\n",
    "for text in sents:\n",
    "    tokens_tensor = gpt_tokenizer.encode( text, add_special_tokens=False, return_tensors=\"pt\").to(0) \n",
    "    loss=gpt_model(tokens_tensor, labels=tokens_tensor)[0]\n",
    "    scores.append( \n",
    "        {\"prob\": np.exp(loss.cpu().detach().numpy()), \"text\": text}       \n",
    "    )\n",
    "dp = pd.DataFrame(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "dp.sort_values(\"prob\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.902687</td>\n",
       "      <td>a photo of a person sitting and smiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>87.852638</td>\n",
       "      <td>a photo of a person smiling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>88.414558</td>\n",
       "      <td>a photo of a person smiling and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>88.646149</td>\n",
       "      <td>a photo of a person standing, smiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>92.471436</td>\n",
       "      <td>a photo of a person smiling or smiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>735.416260</td>\n",
       "      <td>a photo of a person \" smiling brightly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>774.525269</td>\n",
       "      <td>a photo of a person - / smiling :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>852.903381</td>\n",
       "      <td>a photo of a person and ; smiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>915.673279</td>\n",
       "      <td>a photo of a person in smiling happily |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1379.007568</td>\n",
       "      <td>a photo of a person'- smiling eyes \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prob                                       text\n",
       "6     86.902687    a photo of a person sitting and smiling\n",
       "10    87.852638               a photo of a person smiling.\n",
       "55    88.414558            a photo of a person smiling and\n",
       "15    88.646149      a photo of a person standing, smiling\n",
       "24    92.471436     a photo of a person smiling or smiling\n",
       "..          ...                                        ...\n",
       "41   735.416260  a photo of a person \" smiling brightly...\n",
       "70   774.525269          a photo of a person - / smiling :\n",
       "69   852.903381          a photo of a person and ; smiling\n",
       "59   915.673279   a photo of a person in smiling happily |\n",
       "80  1379.007568       a photo of a person'- smiling eyes \"\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from domino.emb.clip import get_wiki_words\n",
    "#dp = get_wiki_words(top_k=25_000, eng_only=True).load()\n",
    "dp = get_wiki_words.out().load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from domino.emb.clip import generate_phrases\n",
    "from domino.data.celeba import PHRASE_TEMPLATES"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "phrase_dp = generate_phrases(dp[100:300], templates=PHRASE_TEMPLATES)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93978321e45a4c2bb0305b8fbf04d5ae"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 14.76 GiB total capacity; 13.66 GiB already allocated; 5.75 MiB free; 13.72 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25502/2995374736.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphrase_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPHRASE_TEMPLATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sabri/code/domino/domino/emb/clip.py\u001b[0m in \u001b[0;36mgenerate_phrases\u001b[0;34m(word_dp, templates, device)\u001b[0m\n\u001b[1;32m    193\u001b[0m         }\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     return word_dp[\"word\"].map(\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_batched_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     )\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/provenance.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_provenance_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0margs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/mixins/mapping.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, is_batched_fn, batch_size, drop_last_batch, num_workers, output_type, materialize, pbar, mmap, mmap_path, flush_size, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;31m# Get some information about the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 function_properties = self._inspect_function(\n\u001b[0m\u001b[1;32m     76\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sabri/code/meerkat/meerkat/mixins/inspect_fn.py\u001b[0m in \u001b[0;36m_inspect_function\u001b[0;34m(self, function, with_indices, is_batched_fn, data, indices, materialize, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# lazy import to avoid circular dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sabri/code/domino/domino/emb/clip.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0msorted_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         )\n\u001b[0;32m--> 971\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 )\n\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     ):\n\u001b[0;32m--> 387\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/envs/conda/envs/domino/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 14.76 GiB total capacity; 13.66 GiB already allocated; 5.75 MiB free; 13.72 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "phrase_dp.to_pandas().sort_values(\"prob\").iloc[-15:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>output_phrase</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19.365196</td>\n",
       "      <td>a photo of a person at work.</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.511856</td>\n",
       "      <td>a photo of a person until.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>19.523741</td>\n",
       "      <td>a photo of a person work</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>19.532944</td>\n",
       "      <td>a photo of a person following.</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>19.544060</td>\n",
       "      <td>a photo of a person or people.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>19.562103</td>\n",
       "      <td>a photo of a person people</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>19.627256</td>\n",
       "      <td>a photo of a person following</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>19.633055</td>\n",
       "      <td>a photo of a person life.</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>19.857872</td>\n",
       "      <td>a photo of a person following her ;</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.410408</td>\n",
       "      <td>a photo of a person since.</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.460211</td>\n",
       "      <td>a photo of a person since</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.644299</td>\n",
       "      <td>a photo of a person or family.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20.953772</td>\n",
       "      <td>a photo of a person them</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21.343624</td>\n",
       "      <td>a photo of a person well</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.225666</td>\n",
       "      <td>a photo of a person until</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prob                        output_phrase index\n",
       "49  19.365196         a photo of a person at work.    49\n",
       "10  19.511856           a photo of a person until.    10\n",
       "45  19.523741             a photo of a person work    45\n",
       "64  19.532944       a photo of a person following.    64\n",
       "85  19.544060       a photo of a person or people.    85\n",
       "81  19.562103           a photo of a person people    81\n",
       "63  19.627256        a photo of a person following    63\n",
       "55  19.633055            a photo of a person life.    55\n",
       "65  19.857872  a photo of a person following her ;    65\n",
       "28  20.410408           a photo of a person since.    28\n",
       "27  20.460211            a photo of a person since    27\n",
       "4   20.644299       a photo of a person or family.     4\n",
       "36  20.953772             a photo of a person them    36\n",
       "18  21.343624             a photo of a person well    18\n",
       "9   22.225666            a photo of a person until     9"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('domino': conda)"
  },
  "interpreter": {
   "hash": "0d937a63d09daec3f9548a5c769ccb20edb9c2c1ae2375686b21850f577713d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}