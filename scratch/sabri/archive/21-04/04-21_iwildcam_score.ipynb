{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd06d7bd4c6039f156d838f2caf01fbd8d7d51ef546e5fb1f60e559c6bdf3c7cc94",
   "display_name": "Python 3.8.8 64-bit ('rg-sabri')"
  },
  "metadata": {
   "interpreter": {
    "hash": "6d7bd4c6039f156d838f2caf01fbd8d7d51ef546e5fb1f60e559c6bdf3c7cc94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"TERRA_CONFIG_PATH\"] = \"/home/sabri/code/spr-21/terra_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robustnessgym as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from spr.data.iwildcam import iwildcam_task_config\n",
    "def initialize_torchvision_model(name, d_out, **kwargs):\n",
    "    # get constructor and last layer names\n",
    "    if name == 'wideresnet50':\n",
    "        constructor_name = 'wide_resnet50_2'\n",
    "        last_layer_name = 'fc'\n",
    "    elif name == 'densenet121':\n",
    "        constructor_name = name\n",
    "        last_layer_name = 'classifier'\n",
    "    elif name in ('resnet50', 'resnet34'):\n",
    "        constructor_name = name\n",
    "        last_layer_name = 'fc'\n",
    "    else:\n",
    "        raise ValueError(f'Torchvision model {name} not recognized')\n",
    "    # construct the default model, which has the default last layer\n",
    "    constructor = getattr(torchvision.models, constructor_name)\n",
    "    model = constructor(**kwargs)\n",
    "    # adjust the last layer\n",
    "    d_features = getattr(model, last_layer_name).in_features\n",
    "    if d_out is None:  # want to initialize a featurizer model\n",
    "        last_layer = Identity(d_features)\n",
    "        model.d_out = d_features\n",
    "    else: # want to initialize a classifier for a particular num_classes\n",
    "        last_layer = nn.Linear(d_features, d_out)\n",
    "        model.d_out = d_out\n",
    "    setattr(model, last_layer_name, last_layer)\n",
    "    return model\n",
    "\n",
    "from spr.vision import Classifier\n",
    "model = initialize_torchvision_model(\n",
    "    \"resnet50\", \n",
    "    d_out=iwildcam_task_config[\"num_classes\"]\n",
    ")\n",
    "classifier = Classifier(model=model, metrics=[\"accuracy\"], config=iwildcam_task_config)\n",
    "state_dict = torch.load(\"/home/common/datasets/iwildcam_v2.0/best_model.pth\")\n",
    "classifier.load_state_dict(state_dict[\"algorithm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/common/envs/conda/envs/rg-sabri/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from spr.data.iwildcam import get_iwildcam_model\n",
    "classifier = get_iwildcam_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-04-23 23:14:36,230][WARNING][pip._internal.operations.freeze:72] :: Could not generate requirement for distribution -illow 8.2.0 (/home/common/envs/conda/envs/rg-sabri/lib/python3.8/site-packages): Parse error at \"'-illow=='\": Expected W:(abcd...)\n",
      "task: score, run_id=39\n",
      "Global seed set to 123\n",
      "[2021-04-23 23:14:38,910][INFO][lightning:54] :: Global seed set to 123\n",
      "/home/common/envs/conda/envs/rg-sabri/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "[2021-04-23 23:14:39,025][INFO][lightning:55] :: GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "[2021-04-23 23:14:39,026][INFO][lightning:55] :: TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd91fc44ae1c4127a4caa6e71d110b9c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'valid_accuracy': 0.8341536521911621,\n 'valid_loss': 1.0643936395645142,\n 'valid_macro_f1': 0.20122647285461426,\n 'valid_macro_recall': 0.20635363459587097}\n--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spr.data.iwildcam import iwildcam_task_config, build_iwildcam_df\n",
    "from spr.vision import score\n",
    "#iwildcam_task_config[\"img_transform\"] = transform\n",
    "out = score(\n",
    "    model=classifier,\n",
    "    data_df=build_iwildcam_df.out(),\n",
    "    batch_size=256,\n",
    "    split=\"id_valid\",\n",
    "    **iwildcam_task_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-04-23 22:59:21,598][WARNING][pip._internal.operations.freeze:72] :: Could not generate requirement for distribution -illow 8.2.0 (/home/common/envs/conda/envs/rg-sabri/lib/python3.8/site-packages): Parse error at \"'-illow=='\": Expected W:(abcd...)\n",
      "task: score, run_id=38\n",
      "Global seed set to 123\n",
      "[2021-04-23 22:59:24,451][INFO][lightning:54] :: Global seed set to 123\n",
      "/home/common/envs/conda/envs/rg-sabri/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "[2021-04-23 22:59:24,667][INFO][lightning:55] :: GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "[2021-04-23 22:59:24,668][INFO][lightning:55] :: TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6afeac88651d44aa96b42886a7b2f408"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'valid_accuracy': 0.6154000163078308,\n 'valid_loss': 1.8163567781448364,\n 'valid_macro_f1': 0.14952275156974792,\n 'valid_macro_recall': 0.15714137256145477}\n--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spr.data.iwildcam import iwildcam_task_config, build_iwildcam_df\n",
    "from spr.vision import score\n",
    "#iwildcam_task_config[\"img_transform\"] = transform\n",
    "out = score(\n",
    "    model=classifier,\n",
    "    data_df=build_iwildcam_df.out(),\n",
    "    batch_size=256,\n",
    "    split=\"valid\",\n",
    "    **iwildcam_task_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}